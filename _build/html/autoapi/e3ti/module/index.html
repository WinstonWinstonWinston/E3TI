

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>e3ti.module &mdash; e3ti 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            e3ti
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../guides/examples.html">Examples</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">e3ti</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">e3ti.module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/autoapi/e3ti/module/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-e3ti.module">
<span id="e3ti-module"></span><h1>e3ti.module<a class="headerlink" href="#module-e3ti.module" title="Link to this heading"></a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">e3ti.module.</span></span><span class="sig-name descname"><span class="pre">E3TIModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L8-L139"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pytorch_lightning.LightningModule</span></code></p>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <a class="reference internal" href="#e3ti.module.E3TIModule.to" title="e3ti.module.E3TIModule.to"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to()</span></code></a>, etc.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As per the example above, an <code class="docutils literal notranslate"><span class="pre">__init__()</span></code> call to the parent class
must be made before assignment on the child.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Variables<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Boolean represents whether this module is in training or
evaluation mode.</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>cfg</strong> (<em>omegaconf.DictConfig</em>)</p>
</dd>
</dl>
<p>Initialize internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.cfg">
<span class="sig-name descname"><span class="pre">cfg</span></span><a class="headerlink" href="#e3ti.module.E3TIModule.cfg" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.prior">
<span class="sig-name descname"><span class="pre">prior</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.prior" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.embedder">
<span class="sig-name descname"><span class="pre">embedder</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.embedder" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.model">
<span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.interpolant">
<span class="sig-name descname"><span class="pre">interpolant</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.interpolant" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L22-L37"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.forward" title="Link to this definition"></a></dt>
<dd><p>TODO: Finish return param typing here
Implements a forward pass through the embedders and model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data" title="(in pytorch_geometric v2.7.0)"><em>torch_geometric.data.Data</em></a>) – A torch batch of geometric data objects which come from a data loader.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A new batch object with modified keys containing velocity, score, denoised point etc.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch_geometric.data.Data??</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.configure_optimizers">
<span class="sig-name descname"><span class="pre">configure_optimizers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L39-L62"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.configure_optimizers" title="Link to this definition"></a></dt>
<dd><p>Parses configuration for the optimizer for lightning</p>
<p><a class="reference external" href="https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule.configure_optimizers">https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.core.LightningModule.html#lightning.pytorch.core.LightningModule.configure_optimizers</a></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.training_step">
<span class="sig-name descname"><span class="pre">training_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L64-L86"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.training_step" title="Link to this definition"></a></dt>
<dd><p>Implements a training step.</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>corrupt batch appropriately using interpolant</p></li>
<li><p>call forward</p></li>
<li><p>compute loss</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data" title="(in pytorch_geometric v2.7.0)"><em>torch_geometric.data.Data</em></a>) – A torch batch of geometric data objects which come from a data loader.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of loss values, loss, loss_velocity, and loss_denoiser</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.validation_step">
<span class="sig-name descname"><span class="pre">validation_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L88-L112"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.validation_step" title="Link to this definition"></a></dt>
<dd><p>Implements a validation step.</p>
<blockquote>
<div><ol class="arabic simple">
<li><dl class="simple">
<dt>corrupt batch appropriately using interpolant</dt><dd><p>1a) do so stratified on [0,1]</p>
</dd>
</dl>
</li>
<li><p>call forward</p></li>
<li><p>compute loss</p></li>
</ol>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>torch_geometric.data.Datax</em>) – A torch batch of geometric data objects which come from a data loader.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A dictionary of loss values, loss, loss_velocity, and loss_denoiser</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.predict_step">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">predict_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L114-L128"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.predict_step" title="Link to this definition"></a></dt>
<dd><p>Use the batch of data to perform experiments on the model based off of config</p>
<ol class="arabic simple">
<li><p>parse experiments from config and instantiate experiment objects</p></li>
<li><p>prepare model for experiment (disable dropout, training depedent layers, etc. )</p></li>
<li><p>run experiment</p></li>
<li><p>go back to 2</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data" title="(in pytorch_geometric v2.7.0)"><em>torch_geometric.data.Data</em></a>) – A torch batch of geometric data objects which come from a data loader.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.summarize_cfg">
<span class="sig-name descname"><span class="pre">summarize_cfg</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/e3ti/module.py#L130-L139"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.summarize_cfg" title="Link to this definition"></a></dt>
<dd><p>Produces a print statement summarizing relevant contents within the configuration object.</p>
<p>TODO: Add a experiment summarize call</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__jit_unused_properties__">
<span class="sig-name descname"><span class="pre">__jit_unused_properties__</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">['example_input_array',</span> <span class="pre">'on_gpu',</span> <span class="pre">'current_epoch',</span> <span class="pre">'global_step',</span> <span class="pre">'global_rank',</span> <span class="pre">'local_rank',...</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.__jit_unused_properties__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.CHECKPOINT_HYPER_PARAMS_KEY">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_KEY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hyper_parameters'</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.CHECKPOINT_HYPER_PARAMS_KEY" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.CHECKPOINT_HYPER_PARAMS_NAME">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_NAME</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_name'</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.CHECKPOINT_HYPER_PARAMS_NAME" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.CHECKPOINT_HYPER_PARAMS_TYPE">
<span class="sig-name descname"><span class="pre">CHECKPOINT_HYPER_PARAMS_TYPE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'hparams_type'</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.CHECKPOINT_HYPER_PARAMS_TYPE" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.optimizers">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">pytorch_lightning.core.optimizer.LightningOptimizer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.core.optimizer.LightningOptimizer</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L166-L194"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.optimizers" title="Link to this definition"></a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><span class="pre">torch.optim.optimizer.Optimizer</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><span class="pre">torch.optim.optimizer.Optimizer</span></a><span class="p"><span class="pre">]</span></span></span></span></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">optimizers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">use_pl_optimizer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">MODULE_OPTIMIZERS</span></span></span></dt>
<dd><p>Returns the optimizer(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>use_pl_optimizer</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will wrap the optimizer(s) in a
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningOptimizer</span></code> for automatic handling of precision,
profiling, and counting of step calls for proper logging and checkpointing. It specifically wraps the
<code class="docutils literal notranslate"><span class="pre">step</span></code> method and custom optimizers that don’t have this method are not supported.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A single optimizer, or a list of optimizers in case multiple ones are present.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.lr_schedulers">
<span class="sig-name descname"><span class="pre">lr_schedulers</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L196-L215"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.lr_schedulers" title="Link to this definition"></a></dt>
<dd><p>Returns the learning rate scheduler(s) that are being used during training. Useful for manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A single scheduler, or a list of schedulers in case multiple ones are present, or <code class="docutils literal notranslate"><span class="pre">None</span></code> if no
schedulers were returned in <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_optimizers()</span></code>.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Union[None, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>[pytorch_lightning.utilities.types.LRSchedulerPLType], pytorch_lightning.utilities.types.LRSchedulerPLType]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.trainer">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.Trainer</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.trainer" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pytorch_lightning.Trainer</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.fabric">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">fabric</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">lightning_fabric.Fabric</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.fabric" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[lightning_fabric.Fabric]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.example_input_array">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">example_input_array</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><span class="pre">torch.Tensor</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><span class="pre">tuple</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><span class="pre">dict</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.example_input_array" title="Link to this definition"></a></dt>
<dd><p>The example input array is a specification of what the module can consume in the <a class="reference internal" href="#e3ti.module.E3TIModule.forward" title="e3ti.module.E3TIModule.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> method. The
return type is interpreted as follows:</p>
<ul class="simple">
<li><p>Single tensor: It is assumed the model takes a single argument, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(model.example_input_array)</span></code></p></li>
<li><p>Tuple: The input array should be interpreted as a sequence of positional arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(*model.example_input_array)</span></code></p></li>
<li><p>Dict: The input array represents named keyword arguments, i.e.,
<code class="docutils literal notranslate"><span class="pre">model.forward(**model.example_input_array)</span></code></p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[Union[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.current_epoch">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">current_epoch</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.current_epoch" title="Link to this definition"></a></dt>
<dd><p>The current epoch in the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, or 0 if not attached.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.global_step">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_step</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.global_step" title="Link to this definition"></a></dt>
<dd><p>Total training batches seen across all epochs.</p>
<p>If no Trainer is attached, this property is 0.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.global_rank">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">global_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.global_rank" title="Link to this definition"></a></dt>
<dd><p>The index of the current process across all nodes and devices.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.local_rank">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">local_rank</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><span class="pre">int</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.local_rank" title="Link to this definition"></a></dt>
<dd><p>The index of the current process within a single node.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_gpu">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">on_gpu</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.on_gpu" title="Link to this definition"></a></dt>
<dd><p>Returns <code class="docutils literal notranslate"><span class="pre">True</span></code> if this model is currently located on a GPU.</p>
<p>Useful to set flags around the LightningModule for different CPU vs GPU behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.automatic_optimization">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">automatic_optimization</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.automatic_optimization" title="Link to this definition"></a></dt>
<dd><p>If set to <code class="docutils literal notranslate"><span class="pre">False</span></code> you are responsible for calling <code class="docutils literal notranslate"><span class="pre">.backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">.step()</span></code>, <code class="docutils literal notranslate"><span class="pre">.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.strict_loading">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">strict_loading</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.strict_loading" title="Link to this definition"></a></dt>
<dd><p>Determines how Lightning loads this model using <code class="xref any docutils literal notranslate"><span class="pre">.load_state_dict(...,</span> <span class="pre">strict=model.strict_loading)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)">bool</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.logger">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">logger</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">pytorch_lightning.loggers.Logger</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">lightning_fabric.loggers.Logger</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.logger" title="Link to this definition"></a></dt>
<dd><p>Reference to the logger object in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[Union[pytorch_lightning.loggers.Logger, lightning_fabric.loggers.Logger]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.loggers">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">loggers</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><span class="pre">pytorch_lightning.loggers.Logger</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><span class="pre">lightning_fabric.loggers.Logger</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#e3ti.module.E3TIModule.loggers" title="Link to this definition"></a></dt>
<dd><p>Reference to the list of loggers in the Trainer.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>[pytorch_lightning.loggers.Logger], <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>[lightning_fabric.loggers.Logger]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.device_mesh">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device_mesh</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/distributed.html#torch.distributed.device_mesh.DeviceMesh" title="(in PyTorch v2.8)"><span class="pre">torch.distributed.device_mesh.DeviceMesh</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><span class="pre">None</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.device_mesh" title="Link to this definition"></a></dt>
<dd><p>Strategies like <code class="docutils literal notranslate"><span class="pre">ModelParallelStrategy</span></code> will create a device mesh that can be accessed in the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> hook to parallelize the LightningModule.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Optional[<a class="reference external" href="https://docs.pytorch.org/docs/stable/distributed.html#torch.distributed.device_mesh.DeviceMesh" title="(in PyTorch v2.8)">torch.distributed.device_mesh.DeviceMesh</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.print">
<span class="sig-name descname"><span class="pre">print</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L364-L382"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.print" title="Link to this definition"></a></dt>
<dd><p>Prints only from process 0. Use this in any distributed mode to log only once.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> (<em>Any</em>) – The thing to print. The same as for Python’s built-in print function.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – The same as for Python’s built-in print function.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;in forward&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.log">
<span class="sig-name descname"><span class="pre">log</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_attribute</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L384-L548"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.log" title="Link to this definition"></a></dt>
<dd><p>Log a key, value pair.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s1">&#39;train_loss&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
<p>The default behavior per hook is documented here: <span class="xref std std-ref">extensions/logging:Automatic Logging</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – key to log. Must be identical across all processes if using DDP or any other distributed strategy.</p></li>
<li><p><strong>value</strong> (<em>pytorch_lightning.utilities.types._METRIC</em>) – value to log. Can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, or a <code class="docutils literal notranslate"><span class="pre">Metric</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress bar.</p></li>
<li><p><strong>logger</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics. The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto detach the graph.</p></li>
<li><p><strong>sync_dist</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across devices. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – the DDP group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple dataloaders). If False, user needs to give unique names for
each dataloader to not mix the values.</p></li>
<li><p><strong>batch_size</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – Current batch_size. This will be directly inferred from the loaded batch,
but for some data structures you might need to explicitly provide it.</p></li>
<li><p><strong>metric_attribute</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – To restore the metric state, Lightning requires the reference of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.Metric</span></code> in your model. This is found automatically if it is a model attribute.</p></li>
<li><p><strong>rank_zero_only</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Tells Lightning if you are calling <code class="docutils literal notranslate"><span class="pre">self.log</span></code> from every process (default) or only from
rank 0. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, you won’t be able to use this metric as a monitor in callbacks
(e.g., early stopping). Warning: Improper use can lead to deadlocks! See
<span class="xref std std-ref">Advanced Logging</span> for more details.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.log_dict">
<span class="sig-name descname"><span class="pre">log_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dictionary</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prog_bar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">on_epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce_fx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_graph</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_dist_group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rank_zero_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L550-L628"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.log_dict" title="Link to this definition"></a></dt>
<dd><p>Log a dictionary of values at once.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">acc</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="s1">&#39;metric_n&#39;</span><span class="p">:</span> <span class="n">metric_n</span><span class="p">}</span>
<span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dictionary</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping" title="(in Python v3.13)"><em>collections.abc.Mapping</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>pytorch_lightning.utilities.types._METRIC</em><em>]</em><em>, </em><em>torchmetrics.MetricCollection</em><em>]</em>) – key value pairs.
Keys must be identical across all processes if using DDP or any other distributed strategy.
The values can be a <code class="docutils literal notranslate"><span class="pre">float</span></code>, <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="docutils literal notranslate"><span class="pre">Metric</span></code>, or <code class="docutils literal notranslate"><span class="pre">MetricCollection</span></code>.</p></li>
<li><p><strong>prog_bar</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the progress base.</p></li>
<li><p><strong>logger</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs to the logger.</p></li>
<li><p><strong>on_step</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs at this step.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for training_step but not validation/test_step.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>on_epoch</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> logs epoch accumulated metrics.
<code class="docutils literal notranslate"><span class="pre">None</span></code> auto-logs for val/test step but not <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.
The default value is determined by the hook.
See <span class="xref std std-ref">extensions/logging:Automatic Logging</span> for details.</p></li>
<li><p><strong>reduce_fx</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Callable</em><em>[</em><em>[</em><em>Any</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – reduction function over step values for end of epoch. <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.mean()</span></code> by default.</p></li>
<li><p><strong>enable_graph</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will not auto-detach the graph</p></li>
<li><p><strong>sync_dist</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, reduces the metric across GPUs/TPUs. Use with care as this may lead to a significant
communication overhead.</p></li>
<li><p><strong>sync_dist_group</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – the ddp group to sync across.</p></li>
<li><p><strong>add_dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, appends the index of the current dataloader to
the name (when using multiple). If <code class="docutils literal notranslate"><span class="pre">False</span></code>, user needs to give unique names for
each dataloader to not mix values.</p></li>
<li><p><strong>batch_size</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em>) – Current batch size. This will be directly inferred from the loaded batch,
but some data structures might need to explicitly provide it.</p></li>
<li><p><strong>rank_zero_only</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Tells Lightning if you are calling <code class="docutils literal notranslate"><span class="pre">self.log</span></code> from every process (default) or only from
rank 0. If <code class="docutils literal notranslate"><span class="pre">True</span></code>, you won’t be able to use this metric as a monitor in callbacks
(e.g., early stopping). Warning: Improper use can lead to deadlocks! See
<span class="xref std std-ref">Advanced Logging</span> for more details.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.all_gather">
<span class="sig-name descname"><span class="pre">all_gather</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_grads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L670-L692"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.all_gather" title="Link to this definition"></a></dt>
<dd><p>Gather tensors or collections of tensors from multiple processes.</p>
<p>This method needs to be called on all processes and the tensors need to have the same shape across all
processes, otherwise your program will stall forever.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>torch.Tensor</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><em>tuple</em></a><em>]</em>) – int, float, tensor of shape (batch, …), or a (possibly nested) collection thereof.</p></li>
<li><p><strong>group</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – the process group to gather results from. Defaults to all processes (world)</p></li>
<li><p><strong>sync_grads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – flag that allows users to synchronize gradients for the all_gather operation</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor of shape (world_size, batch, …), or if the input was a collection
the output will also be a collection with tensors of this shape. For the special case where
world_size is 1, no additional dimension is added to the tensor(s).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)">list</a>, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)">tuple</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.test_step">
<span class="sig-name descname"><span class="pre">test_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L846-L926"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.test_step" title="Link to this definition"></a></dt>
<dd><p>Operates on a single batch of data from the test set. In this step you’d normally generate examples or
calculate anything of interest such as accuracy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – The output of your data iterable, normally a <a class="reference external" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a>.</p></li>
<li><p><strong>batch_idx</strong> – The index of this batch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader that produced this batch.
(only if multiple dataloaders used)</p></li>
<li><p><strong>args</strong> (<em>Any</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> - The loss tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dict</span></code> - A dictionary. Can include any keys, but must include the key <code class="docutils literal notranslate"><span class="pre">'loss'</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">None</span></code> - Skip to the next batch.</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pytorch_lightning.utilities.types.STEP_OUTPUT</p>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if you have one test dataloader:</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span> <span class="o">...</span>


<span class="c1"># if you have multiple test dataloaders:</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span> <span class="o">...</span>
</pre></div>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 1: A single test dataset</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># log 6 example images</span>
    <span class="c1"># or generated text... or whatever</span>
    <span class="n">sample_imgs</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:</span><span class="mi">6</span><span class="p">]</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">sample_imgs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="s1">&#39;example_images&#39;</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs!</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="s1">&#39;test_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;test_acc&#39;</span><span class="p">:</span> <span class="n">test_acc</span><span class="p">})</span>
</pre></div>
</div>
<p>If you pass in multiple test dataloaders, <a class="reference internal" href="#e3ti.module.E3TIModule.test_step" title="e3ti.module.E3TIModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> will have an additional argument. We recommend
setting the default value of 0 so that you can quickly switch between single and multiple dataloaders.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># CASE 2: multiple test dataloaders</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># dataloader_idx tells you which dataset this is.</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="c1"># implement your own</span>
    <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss0</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss1</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># calculate acc</span>
    <span class="n">labels_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">labels_hat</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span><span class="p">)</span>

    <span class="c1"># log the outputs separately for each dataloader</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">({</span><span class="sa">f</span><span class="s2">&quot;test_loss_</span><span class="si">{</span><span class="n">dataloader_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;test_acc_</span><span class="si">{</span><span class="n">dataloader_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">acc</span><span class="p">})</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need to test you don’t need to implement this method.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the <a class="reference internal" href="#e3ti.module.E3TIModule.test_step" title="e3ti.module.E3TIModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a> is called, the model has been put in eval mode and
PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
to training mode and gradients are enabled.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.configure_callbacks">
<span class="sig-name descname"><span class="pre">configure_callbacks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L968-L986"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.configure_callbacks" title="Link to this definition"></a></dt>
<dd><p>Configure model-specific callbacks. When the model gets attached, e.g., when <code class="docutils literal notranslate"><span class="pre">.fit()</span></code> or <code class="docutils literal notranslate"><span class="pre">.test()</span></code> gets
called, the list or a callback returned here will be merged with the list of callbacks passed to the Trainer’s
<code class="docutils literal notranslate"><span class="pre">callbacks</span></code> argument. If a callback returned here has the same type as one or several callbacks already
present in the Trainer’s callbacks list, it will take priority and replace them. In addition, Lightning will
make sure <code class="xref py py-class docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callbacks run last.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A callback or a list of callbacks which will extend the list of callbacks in the Trainer.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Union[<a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence" title="(in Python v3.13)">collections.abc.Sequence</a>[pytorch_lightning.callbacks.callback.Callback], pytorch_lightning.callbacks.callback.Callback]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">configure_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">early_stop</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_acc&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
    <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">early_stop</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.manual_backward">
<span class="sig-name descname"><span class="pre">manual_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1090-L1116"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.manual_backward" title="Link to this definition"></a></dt>
<dd><p>Call this directly from your <a class="reference internal" href="#e3ti.module.E3TIModule.training_step" title="e3ti.module.E3TIModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a> when doing optimizations manually. By using this,
Lightning can ensure that all the proper scaling gets applied when using mixed precision.</p>
<p>See <span class="xref std std-ref">manual optimization</span> for more examples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># automatically applies scaling, etc...</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>torch.Tensor</em></a>) – The tensor on which to compute gradients. Must have a graph attached.</p></li>
<li><p><strong>*args</strong> (<em>Any</em>) – Additional positional arguments to be forwarded to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></a></p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – Additional keyword arguments to be forwarded to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.backward.html#torch.Tensor.backward" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward()</span></code></a></p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.backward">
<span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1118-L1135"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.backward" title="Link to this definition"></a></dt>
<dd><p>Called to perform backward on the loss returned in <a class="reference internal" href="#e3ti.module.E3TIModule.training_step" title="e3ti.module.E3TIModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. Override this hook with your own
implementation if you need to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>loss</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>torch.Tensor</em></a>) – The loss tensor returned by <a class="reference internal" href="#e3ti.module.E3TIModule.training_step" title="e3ti.module.E3TIModule.training_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">training_step()</span></code></a>. If gradient accumulation is used, the loss here
holds the normalized value (scaled by 1 / accumulation steps).</p></li>
<li><p><strong>args</strong> (<em>Any</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">):</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.toggle_optimizer">
<span class="sig-name descname"><span class="pre">toggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1137-L1164"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.toggle_optimizer" title="Link to this definition"></a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup.</p>
<p>It works with <a class="reference internal" href="#e3ti.module.E3TIModule.untoggle_optimizer" title="e3ti.module.E3TIModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> to make sure <code class="docutils literal notranslate"><span class="pre">param_requires_grad_state</span></code> is properly reset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a><em>, </em><em>pytorch_lightning.core.optimizer.LightningOptimizer</em><em>]</em>) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.untoggle_optimizer">
<span class="sig-name descname"><span class="pre">untoggle_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1166-L1180"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.untoggle_optimizer" title="Link to this definition"></a></dt>
<dd><p>Resets the state of required gradients that were toggled with <a class="reference internal" href="#e3ti.module.E3TIModule.toggle_optimizer" title="e3ti.module.E3TIModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a><em>, </em><em>pytorch_lightning.core.optimizer.LightningOptimizer</em><em>]</em>) – The optimizer to untoggle.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.toggled_optimizer">
<span class="sig-name descname"><span class="pre">toggled_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/contextlib.py#L1182-L1206"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.toggled_optimizer" title="Link to this definition"></a></dt>
<dd><p>Makes sure only the gradients of the current optimizer’s parameters are calculated in the training step to
prevent dangling gradients in multiple-optimizer setup. Combines <a class="reference internal" href="#e3ti.module.E3TIModule.toggle_optimizer" title="e3ti.module.E3TIModule.toggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">toggle_optimizer()</span></code></a> and
<a class="reference internal" href="#e3ti.module.E3TIModule.untoggle_optimizer" title="e3ti.module.E3TIModule.untoggle_optimizer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">untoggle_optimizer()</span></code></a> into context manager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a><em>, </em><em>pytorch_lightning.core.optimizer.LightningOptimizer</em><em>]</em>) – The optimizer to toggle.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Generator" title="(in Python v3.13)">collections.abc.Generator</a></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">toggled_optimizer</span><span class="p">(</span><span class="n">opt</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.clip_gradients">
<span class="sig-name descname"><span class="pre">clip_gradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1208-L1274"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.clip_gradients" title="Link to this definition"></a></dt>
<dd><p>Handles gradient clipping internally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Do not override this method. If you want to customize gradient clipping, consider using
<a class="reference internal" href="#e3ti.module.E3TIModule.configure_gradient_clipping" title="e3ti.module.E3TIModule.configure_gradient_clipping"><code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_gradient_clipping()</span></code></a> method.</p></li>
<li><p>For manual optimization (<code class="docutils literal notranslate"><span class="pre">self.automatic_optimization</span> <span class="pre">=</span> <span class="pre">False</span></code>), if you want to use
gradient clipping, consider calling
<code class="docutils literal notranslate"><span class="pre">self.clip_gradients(opt,</span> <span class="pre">gradient_clip_val=0.5,</span> <span class="pre">gradient_clip_algorithm=&quot;norm&quot;)</span></code>
manually in the training step.</p></li>
</ul>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>]</em><em>]</em>) – The value at which to clip gradients.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The gradient clipping algorithm to use. Pass <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;value&quot;</span></code>
to clip by value, and <code class="docutils literal notranslate"><span class="pre">gradient_clip_algorithm=&quot;norm&quot;</span></code> to clip by norm.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.configure_gradient_clipping">
<span class="sig-name descname"><span class="pre">configure_gradient_clipping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gradient_clip_algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1276-L1305"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.configure_gradient_clipping" title="Link to this definition"></a></dt>
<dd><p>Perform gradient clipping for the optimizer parameters. Called before <a class="reference internal" href="#e3ti.module.E3TIModule.optimizer_step" title="e3ti.module.E3TIModule.optimizer_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">optimizer_step()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a>) – Current optimizer being used.</p></li>
<li><p><strong>gradient_clip_val</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a><em>]</em><em>]</em>) – The value at which to clip gradients. By default, value passed in Trainer
will be available here.</p></li>
<li><p><strong>gradient_clip_algorithm</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – The gradient clipping algorithm to use. By default, value
passed in Trainer will be available here.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">configure_gradient_clipping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="p">,</span> <span class="n">gradient_clip_algorithm</span><span class="p">):</span>
    <span class="c1"># Implement your own custom logic to clip gradients</span>
    <span class="c1"># You can call `self.clip_gradients` with your settings:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradients</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">gradient_clip_algorithm</span><span class="o">=</span><span class="n">gradient_clip_algorithm</span>
    <span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.lr_scheduler_step">
<span class="sig-name descname"><span class="pre">lr_scheduler_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1307-L1333"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.lr_scheduler_step" title="Link to this definition"></a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
each scheduler. By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and as shown in the example for each scheduler based on
its <code class="docutils literal notranslate"><span class="pre">interval</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scheduler</strong> (<em>pytorch_lightning.utilities.types.LRSchedulerTypeUnion</em>) – Learning rate scheduler.</p></li>
<li><p><strong>metric</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – Value of the monitor used for schedulers like <code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">metric</span><span class="p">)</span>

<span class="c1"># Alternative way to update schedulers if it requires an epoch value</span>
<span class="k">def</span><span class="w"> </span><span class="nf">lr_scheduler_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">metric</span><span class="p">):</span>
    <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.optimizer_step">
<span class="sig-name descname"><span class="pre">optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_closure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1335-L1366"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.optimizer_step" title="Link to this definition"></a></dt>
<dd><p>Override this method to adjust the default way the <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> calls
the optimizer.</p>
<p>By default, Lightning calls <code class="docutils literal notranslate"><span class="pre">step()</span></code> and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code> as shown in the example.
This method (and <code class="docutils literal notranslate"><span class="pre">zero_grad()</span></code>) won’t be called during the accumulation phase when
<code class="docutils literal notranslate"><span class="pre">Trainer(accumulate_grad_batches</span> <span class="pre">!=</span> <span class="pre">1)</span></code>. Overriding this hook has no benefit with manual optimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a><em>, </em><em>pytorch_lightning.core.optimizer.LightningOptimizer</em><em>]</em>) – A PyTorch optimizer</p></li>
<li><p><strong>optimizer_closure</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>[</em><em>[</em><em>]</em><em>, </em><em>Any</em><em>]</em><em>]</em>) – The optimizer closure. This closure must be executed as it includes the
calls to <code class="docutils literal notranslate"><span class="pre">training_step()</span></code>, <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>, and <code class="docutils literal notranslate"><span class="pre">backward()</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">optimizer_closure</span><span class="p">):</span>
    <span class="c1"># Add your custom logic to run directly before `optimizer.step()`</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="o">=</span><span class="n">optimizer_closure</span><span class="p">)</span>

    <span class="c1"># Add your custom logic to run directly after `optimizer.step()`</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.optimizer_zero_grad">
<span class="sig-name descname"><span class="pre">optimizer_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1368-L1389"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.optimizer_zero_grad" title="Link to this definition"></a></dt>
<dd><p>Override this method to change the default behaviour of <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Current epoch</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – Index of current batch</p></li>
<li><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a>) – A PyTorch optimizer</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="k">def</span><span class="w"> </span><span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="c1"># Set gradients to `None` instead of zero to improve performance (not required on `torch&gt;=2.0.0`).</span>
<span class="k">def</span><span class="w"> </span><span class="nf">optimizer_zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code></a> for the explanation of the above example.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.freeze">
<span class="sig-name descname"><span class="pre">freeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1391-L1403"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.freeze" title="Link to this definition"></a></dt>
<dd><p>Freeze all params for inference.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.unfreeze">
<span class="sig-name descname"><span class="pre">unfreeze</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1405-L1417"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.unfreeze" title="Link to this definition"></a></dt>
<dd><p>Unfreeze all parameters for training.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.to_onnx">
<span class="sig-name descname"><span class="pre">to_onnx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_sample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/utils/_contextlib.py#L1426-L1483"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.to_onnx" title="Link to this definition"></a></dt>
<dd><p>Saves the model in ONNX format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.13)"><em>pathlib.Path</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/io.html#io.BytesIO" title="(in Python v3.13)"><em>io.BytesIO</em></a><em>, </em><em>None</em><em>]</em>) – The path of the file the onnx model should be saved to. Default: None (no file saved).</p></li>
<li><p><strong>input_sample</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – An input for tracing. Default: None (Use self.example_input_array)</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – Will be passed to torch.onnx.export function.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[<a class="reference external" href="https://docs.pytorch.org/docs/stable/onnx_dynamo.html#torch.onnx.ONNXProgram" title="(in PyTorch v2.8)">torch.onnx.ONNXProgram</a>]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">input_sample</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_onnx</span><span class="p">(</span><span class="s2">&quot;export.onnx&quot;</span><span class="p">,</span> <span class="n">input_sample</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.to_torchscript">
<span class="sig-name descname"><span class="pre">to_torchscript</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'script'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/utils/_contextlib.py#L1485-L1571"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.to_torchscript" title="Link to this definition"></a></dt>
<dd><p>By default compiles the whole model to a <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ScriptModule</span></code></a>. If you want to use tracing,
please provided the argument <code class="docutils literal notranslate"><span class="pre">method='trace'</span></code> and make sure that either the <code class="xref any docutils literal notranslate"><span class="pre">example_inputs</span></code> argument is
provided, or the model has <a class="reference internal" href="#e3ti.module.E3TIModule.example_input_array" title="e3ti.module.E3TIModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a> set. If you would like to customize the modules that are
scripted you should override this method. In case you want to return multiple modules, we recommend using a
dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_path</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.13)"><em>pathlib.Path</em></a><em>]</em><em>]</em>) – Path where to save the torchscript. Default: None (no file saved).</p></li>
<li><p><strong>method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>) – Whether to use TorchScript’s script or trace method. Default: ‘script’</p></li>
<li><p><strong>example_inputs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – An input to be used to do tracing when method is set to ‘trace’.
Default: None (uses <a class="reference internal" href="#e3ti.module.E3TIModule.example_input_array" title="e3ti.module.E3TIModule.example_input_array"><code class="xref py py-attr docutils literal notranslate"><span class="pre">example_input_array</span></code></a>)</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – Additional arguments that will be passed to the <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.script.html#torch.jit.script" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.script()</span></code></a> or
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.jit.trace()</span></code></a> function.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Union[torch.ScriptModule, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, torch.ScriptModule]]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Requires the implementation of the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p></li>
<li><p>The exported script will be set to evaluation mode.</p></li>
<li><p>It is recommended that you install the latest supported version of PyTorch
to use this feature without limitations. See also the <a class="reference external" href="https://docs.pytorch.org/docs/stable/jit.html#module-torch.jit" title="(in PyTorch v2.8)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.jit</span></code></a>
documentation for supported features.</p></li>
</ul>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SimpleModel</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleModel</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span><span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">to_torchscript</span><span class="p">(</span>
    <span class="n">file_path</span><span class="o">=</span><span class="s2">&quot;model_trace.pt&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;trace&#39;</span><span class="p">,</span> <span class="n">example_inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>This LightningModule as a torchscript, regardless of whether <code class="xref any docutils literal notranslate"><span class="pre">file_path</span></code> is
defined or not.</p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>file_path</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.13)"><em>pathlib.Path</em></a><em>]</em><em>]</em>)</p></li>
<li><p><strong>method</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>)</p></li>
<li><p><strong>example_inputs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[torch.ScriptModule, <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, torch.ScriptModule]]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.load_from_checkpoint">
<span class="sig-name descname"><span class="pre">load_from_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hparams_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/utilities/model_helpers.py#L1573-L1670"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.load_from_checkpoint" title="Link to this definition"></a></dt>
<dd><p>Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments
passed to <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  in the checkpoint under <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<p>Any arguments specified through **kwargs will override args stored in <code class="docutils literal notranslate"><span class="pre">&quot;hyper_parameters&quot;</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>checkpoint_path</strong> (<em>Union</em><em>[</em><em>lightning_fabric.utilities.types._PATH</em><em>, </em><em>IO</em><em>]</em>) – Path to checkpoint. This can also be a URL, or file-like object</p></li>
<li><p><strong>map_location</strong> (<em>lightning_fabric.utilities.types._MAP_LOCATION_TYPE</em>) – If your checkpoint saved a GPU model and you now load on CPUs
or a different number of GPUs, use this to map to the new setup.
The behaviour is the same as in <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.load.html#torch.load" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.load()</span></code></a>.</p></li>
<li><p><strong>hparams_file</strong> (<em>Optional</em><em>[</em><em>lightning_fabric.utilities.types._PATH</em><em>]</em>) – <p>Optional path to a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> or <code class="docutils literal notranslate"><span class="pre">.csv</span></code> file with hierarchical structure
as in this example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">drop_prob</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="n">dataloader</span><span class="p">:</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="mi">32</span>
</pre></div>
</div>
<p>You most likely won’t need this since Lightning will always save the hyperparameters
to the checkpoint.
However, if your checkpoint weights don’t have the hyperparameters saved,
use this method to pass in a <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file with the hparams you’d like to use.
These will be converted into a <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a> and passed into your
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> for use.</p>
<p>If your model’s <code class="docutils literal notranslate"><span class="pre">hparams</span></code> argument is <a class="reference external" href="https://docs.python.org/3/library/argparse.html#argparse.Namespace" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Namespace</span></code></a>
and <code class="docutils literal notranslate"><span class="pre">.yaml</span></code> file has hierarchical structure, you need to refactor your model to treat
<code class="docutils literal notranslate"><span class="pre">hparams</span></code> as <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>.</p>
</p></li>
<li><p><strong>strict</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>]</em>) – Whether to strictly enforce that the keys in <code class="xref py py-attr docutils literal notranslate"><span class="pre">checkpoint_path</span></code> match the keys
returned by this module’s state dict. Defaults to <code class="docutils literal notranslate"><span class="pre">True</span></code> unless <code class="docutils literal notranslate"><span class="pre">LightningModule.strict_loading</span></code> is
set, in which case it defaults to the value of <code class="docutils literal notranslate"><span class="pre">LightningModule.strict_loading</span></code>.</p></li>
<li><p><strong>**kwargs</strong> (<em>Any</em>) – Any extra keyword args needed to init the model. Can also be used to override saved
hyperparameter values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance with loaded weights and hyperparameters (if available).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>typing_extensions.Self</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> is a <strong>class</strong> method. You should use your <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code>
<strong>class</strong> to call it instead of the <code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> instance, or a
<code class="docutils literal notranslate"><span class="pre">TypeError</span></code> will be raised.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To ensure all layers can be loaded from the checkpoint, this function will call
<code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> directly after instantiating the
model if this hook is overridden in your LightningModule. However, note that <code class="docutils literal notranslate"><span class="pre">load_from_checkpoint</span></code> does
not support loading sharded checkpoints, and you may run out of memory if the model is too large. In this
case, consider loading through the Trainer via <code class="docutils literal notranslate"><span class="pre">.fit(ckpt_path=...)</span></code>.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load weights without mapping ...</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span><span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">)</span>

<span class="c1"># or load weights mapping all weights from GPU 1 to GPU 0 ...</span>
<span class="n">map_location</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span>
<span class="p">)</span>

<span class="c1"># or load weights and hyperparameters from separate files.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="s1">&#39;path/to/checkpoint.ckpt&#39;</span><span class="p">,</span>
    <span class="n">hparams_file</span><span class="o">=</span><span class="s1">&#39;/path/to/hparams_file.yaml&#39;</span>
<span class="p">)</span>

<span class="c1"># override some of the params with new values</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyLightningModule</span><span class="o">.</span><span class="n">load_from_checkpoint</span><span class="p">(</span>
    <span class="n">PATH</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">pretrained_ckpt_path</span><span class="o">=</span><span class="n">NEW_PATH</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># predict</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">pretrained_model</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__getstate__">
<span class="sig-name descname"><span class="pre">__getstate__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/module.py#L1672-L1676"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__getstate__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)">dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, Any]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.dtype">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dtype</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.8)"><span class="pre">torch.dtype</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.dtype" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Union[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.8)">torch.dtype</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.device">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.8)"><span class="pre">torch.device</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.device" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.8)">torch.device</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.to">
<span class="sig-name descname"><span class="pre">to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L49-L55"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.to" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.to()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Any</em>)</p></li>
<li><p><strong>kwargs</strong> (<em>Any</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.cuda">
<span class="sig-name descname"><span class="pre">cuda</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L57-L76"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.cuda" title="Link to this definition"></a></dt>
<dd><p>Moves all model parameters and buffers to the GPU. This also makes associated parameters and buffers
different objects. So it should be called before constructing optimizer if the module will live on GPU while
being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.8)"><em>torch.device</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>]</em><em>]</em>) – If specified, all parameters will be copied to that device. If <a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.13)"><code class="xref any docutils literal notranslate"><span class="pre">None</span></code></a>, the current CUDA device
index will be used.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.cpu">
<span class="sig-name descname"><span class="pre">cpu</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L78-L82"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.cpu" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cpu" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.cpu()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.type">
<span class="sig-name descname"><span class="pre">type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dst_type</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L84-L88"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.type" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.type" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.type()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>dst_type</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="(in PyTorch v2.8)"><em>torch.dtype</em></a><em>]</em>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.float">
<span class="sig-name descname"><span class="pre">float</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L90-L94"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.float" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.float" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.float()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.double">
<span class="sig-name descname"><span class="pre">double</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L96-L100"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.double" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.double" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.double()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.half">
<span class="sig-name descname"><span class="pre">half</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/lightning_fabric/utilities/device_dtype_mixin.py#L102-L106"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.half" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.half" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.nn.Module.half()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>typing_extensions.Self</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.dump_patches">
<span class="sig-name descname"><span class="pre">dump_patches</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.dump_patches" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.training" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.call_super_init">
<span class="sig-name descname"><span class="pre">call_super_init</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.call_super_init" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_buffer">
<span class="sig-name descname"><span class="pre">register_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">persistent</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L519-L579"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_buffer" title="Link to this definition"></a></dt>
<dd><p>Add a buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the module’s state. Buffers, by
default, are persistent and will be saved alongside parameters. This
behavior can be changed by setting <code class="xref py py-attr docutils literal notranslate"><span class="pre">persistent</span></code> to <code class="docutils literal notranslate"><span class="pre">False</span></code>. The
only difference between a persistent buffer and a non-persistent buffer
is that the latter will not be a part of this module’s
<a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<em>Tensor</em><em> or </em><em>None</em>) – buffer to be registered. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations
that run on buffers, such as <a class="reference internal" href="#e3ti.module.E3TIModule.cuda" title="e3ti.module.E3TIModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>, are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>,
the buffer is <strong>not</strong> included in the module’s <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
<li><p><strong>persistent</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – whether the buffer is part of this module’s
<a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_parameter">
<span class="sig-name descname"><span class="pre">register_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L581-L629"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_parameter" title="Link to this definition"></a></dt>
<dd><p>Add a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<em>Parameter</em><em> or </em><em>None</em>) – parameter to be added to the module. If
<code class="docutils literal notranslate"><span class="pre">None</span></code>, then operations that run on parameters, such as <a class="reference internal" href="#e3ti.module.E3TIModule.cuda" title="e3ti.module.E3TIModule.cuda"><code class="xref py py-attr docutils literal notranslate"><span class="pre">cuda</span></code></a>,
are ignored. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the parameter is <strong>not</strong> included in the
module’s <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.add_module">
<span class="sig-name descname"><span class="pre">add_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L631-L657"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.add_module" title="Link to this definition"></a></dt>
<dd><p>Add a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – child module to be added to the module.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_module">
<span class="sig-name descname"><span class="pre">register_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L659-L661"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_module" title="Link to this definition"></a></dt>
<dd><p>Alias for <a class="reference internal" href="#e3ti.module.E3TIModule.add_module" title="e3ti.module.E3TIModule.add_module"><code class="xref py py-func docutils literal notranslate"><span class="pre">add_module()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>module</strong> (<em>Optional</em><em>[</em><em>Module</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.get_submodule">
<span class="sig-name descname"><span class="pre">get_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L663-L726"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.get_submodule" title="Link to this definition"></a></dt>
<dd><p>Return the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To check whether or not we have the <code class="docutils literal notranslate"><span class="pre">linear</span></code> submodule, we
would call <code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.linear&quot;)</span></code>. To check whether
we have the <code class="docutils literal notranslate"><span class="pre">conv</span></code> submodule, we would call
<code class="docutils literal notranslate"><span class="pre">get_submodule(&quot;net_b.net_c.conv&quot;)</span></code>.</p>
<p>The runtime of <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> is bounded by the degree
of module nesting in <code class="docutils literal notranslate"><span class="pre">target</span></code>. A query against
<code class="docutils literal notranslate"><span class="pre">named_modules</span></code> achieves the same result, but it is O(N) in
the number of transitive modules. So, for a simple check to see
if some submodule exists, <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> should always be
used.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.nn.Module</em> – The submodule referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.set_submodule">
<span class="sig-name descname"><span class="pre">set_submodule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L728-L785"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.set_submodule" title="Link to this definition"></a></dt>
<dd><p>Set the submodule given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>For example, let’s say you have an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code> that
looks like this:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>A(
    (net_b): Module(
        (net_c): Module(
            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))
        )
        (linear): Linear(in_features=100, out_features=200, bias=True)
    )
)
</pre></div>
</div>
<p>(The diagram shows an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> <code class="docutils literal notranslate"><span class="pre">A</span></code>. <code class="docutils literal notranslate"><span class="pre">A</span></code> has a nested
submodule <code class="docutils literal notranslate"><span class="pre">net_b</span></code>, which itself has two submodules <code class="docutils literal notranslate"><span class="pre">net_c</span></code>
and <code class="docutils literal notranslate"><span class="pre">linear</span></code>. <code class="docutils literal notranslate"><span class="pre">net_c</span></code> then has a submodule <code class="docutils literal notranslate"><span class="pre">conv</span></code>.)</p>
<p>To overide the <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> with a new submodule <code class="docutils literal notranslate"><span class="pre">Linear</span></code>, you
would call
<code class="docutils literal notranslate"><span class="pre">set_submodule(&quot;net_b.net_c.conv&quot;,</span> <span class="pre">nn.Linear(33,</span> <span class="pre">16))</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The fully-qualified string name of the submodule
to look for. (See above example for how to specify a
fully-qualified string.)</p></li>
<li><p><strong>module</strong> (<em>Module</em>) – The module to set the submodule to.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.13)"><strong>ValueError</strong></a> – If the target string is empty</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code></p></li>
</ul>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.get_parameter">
<span class="sig-name descname"><span class="pre">get_parameter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L787-L821"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.get_parameter" title="Link to this definition"></a></dt>
<dd><p>Return the parameter given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The fully-qualified string name of the Parameter
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.nn.Parameter</em> – The Parameter referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – If the target string references an invalid
path or resolves to something that is not an
<code class="docutils literal notranslate"><span class="pre">nn.Parameter</span></code></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="(in PyTorch v2.8)">torch.nn.parameter.Parameter</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.get_buffer">
<span class="sig-name descname"><span class="pre">get_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L823-L857"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.get_buffer" title="Link to this definition"></a></dt>
<dd><p>Return the buffer given by <code class="docutils literal notranslate"><span class="pre">target</span></code> if it exists, otherwise throw an error.</p>
<p>See the docstring for <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for a more detailed
explanation of this method’s functionality as well as how to
correctly specify <code class="docutils literal notranslate"><span class="pre">target</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – The fully-qualified string name of the buffer
to look for. (See <code class="docutils literal notranslate"><span class="pre">get_submodule</span></code> for how to specify a
fully-qualified string.)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.Tensor</em> – The buffer referenced by <code class="docutils literal notranslate"><span class="pre">target</span></code></p>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#AttributeError" title="(in Python v3.13)"><strong>AttributeError</strong></a> – If the target string references an invalid
path or resolves to something that is not a
buffer</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.get_extra_state">
<span class="sig-name descname"><span class="pre">get_extra_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L859-L878"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.get_extra_state" title="Link to this definition"></a></dt>
<dd><p>Return any extra state to include in the module’s state_dict.</p>
<p>Implement this and a corresponding <a class="reference internal" href="#e3ti.module.E3TIModule.set_extra_state" title="e3ti.module.E3TIModule.set_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_extra_state()</span></code></a> for your module
if you need to store extra state. This function is called when building the
module’s <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a>.</p>
<p>Note that extra state should be picklable to ensure working serialization
of the state_dict. We only provide provide backwards compatibility guarantees
for serializing Tensors; other objects may break backwards compatibility if
their serialized pickled form changes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>object</em> – Any extra state to store in the module’s state_dict</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.set_extra_state">
<span class="sig-name descname"><span class="pre">set_extra_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L880-L895"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.set_extra_state" title="Link to this definition"></a></dt>
<dd><p>Set extra state contained in the loaded <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<p>This function is called from <a class="reference internal" href="#e3ti.module.E3TIModule.load_state_dict" title="e3ti.module.E3TIModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> to handle any extra state
found within the <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">state_dict</span></code></a>. Implement this function and a corresponding
<a class="reference internal" href="#e3ti.module.E3TIModule.get_extra_state" title="e3ti.module.E3TIModule.get_extra_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_extra_state()</span></code></a> for your module if you need to store extra state within its
<a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">state_dict</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – Extra state from the <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">state_dict</span></code></a></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fn</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L992-L1031"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.apply" title="Link to this definition"></a></dt>
<dd><p>Apply <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>) as well as self.</p>
<p>Typical use includes initializing the parameters of a model
(see also <a class="reference external" href="https://docs.pytorch.org/docs/stable/nn.init.html#nn-init-doc" title="(in PyTorch v2.8)"><span>torch.nn.init</span></a>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>fn</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[1., 1.],</span>
<span class="go">        [1., 1.]], requires_grad=True)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.ipu">
<span class="sig-name descname"><span class="pre">ipu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1052-L1069"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.ipu" title="Link to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the IPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on IPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.xpu">
<span class="sig-name descname"><span class="pre">xpu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1071-L1088"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.xpu" title="Link to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the XPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on XPU while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.mtia">
<span class="sig-name descname"><span class="pre">mtia</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1090-L1107"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.mtia" title="Link to this definition"></a></dt>
<dd><p>Move all model parameters and buffers to the MTIA.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on MTIA while being optimized.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.bfloat16">
<span class="sig-name descname"><span class="pre">bfloat16</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1167-L1176"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.bfloat16" title="Link to this definition"></a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">bfloat16</span></code> datatype.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em> – self</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.to_empty">
<span class="sig-name descname"><span class="pre">to_empty</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1178-L1194"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.to_empty" title="Link to this definition"></a></dt>
<dd><p>Move the parameters and buffers to the specified device without copying storage.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>) – The desired device of the parameters
and buffers in this module.</p></li>
<li><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether parameters and buffers of submodules should
be recursively moved to the specified device.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_full_backward_pre_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1342-L1389"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_full_backward_pre_hook" title="Link to this definition"></a></dt>
<dd><p>Register a backward pre-hook on the module.</p>
<p>The hook will be called every time the gradients for the module are computed.
The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> is a tuple. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the output that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> in
subsequent computations. Entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for
all non-Tensor arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_pre_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code> –     a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.hooks.RemovableHandle</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_backward_hook">
<span class="sig-name descname"><span class="pre">register_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1391-L1415"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_backward_hook" title="Link to this definition"></a></dt>
<dd><p>Register a backward hook on the module.</p>
<p>This function is deprecated in favor of <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_full_backward_hook()</span></code></a> and
the behavior of this function will change in future versions.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code> –     a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>hook</strong> (<em>Callable</em><em>[</em><em>[</em><em>Module</em><em>, </em><em>_grad_t</em><em>, </em><em>_grad_t</em><em>]</em><em>, </em><em>Union</em><em>[</em><em>None</em><em>, </em><em>_grad_t</em><em>]</em><em>]</em>)</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.hooks.RemovableHandle</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_full_backward_hook">
<span class="sig-name descname"><span class="pre">register_full_backward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1417-L1477"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_full_backward_hook" title="Link to this definition"></a></dt>
<dd><p>Register a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to a module
are computed, i.e. the hook will execute if and only if the gradients with
respect to module outputs are computed. The hook should have the following
signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> are tuples that contain the gradients
with respect to the inputs and outputs respectively. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in
subsequent computations. <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> will only correspond to the inputs given
as positional arguments and all kwarg arguments are ignored. Entries
in <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will be <code class="docutils literal notranslate"><span class="pre">None</span></code> for all non-Tensor
arguments.</p>
<p>For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Modifying inputs or outputs inplace is not allowed when using backward hooks and
will raise an error.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user-defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">backward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_full_backward_hook()</span></code> will fire before
all hooks registered by this method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code> –     a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.hooks.RemovableHandle</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_forward_pre_hook">
<span class="sig-name descname"><span class="pre">register_forward_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1577-L1641"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_forward_pre_hook" title="Link to this definition"></a></dt>
<dd><p>Register a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#e3ti.module.E3TIModule.forward" title="e3ti.module.E3TIModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is false or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
input. User can either return a tuple or a single modified value in the
hook. We will wrap the value into a tuple if a single value is returned
(unless that value is already a tuple). The hook should have the
following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is true, the forward pre-hook will be passed the
kwargs given to the forward function. And if the hook modifies the
input, both the args and kwargs should be returned. The hook should have
the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">a</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">modified</span> <span class="nb">input</span> <span class="ow">and</span> <span class="n">kwargs</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If true, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired before
all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks
on this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward_pre</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_pre_hook()</span></code> will fire before all
hooks registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If true, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the kwargs
given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code> –     a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.hooks.RemovableHandle</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_forward_hook">
<span class="sig-name descname"><span class="pre">register_forward_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em>, <em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">prepend</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">always_call</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1643-L1710"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_forward_hook" title="Link to this definition"></a></dt>
<dd><p>Register a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#e3ti.module.E3TIModule.forward" title="e3ti.module.E3TIModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code> or not specified, the input contains only
the positional arguments given to the module. Keyword arguments won’t be
passed to the hooks and only to the <code class="docutils literal notranslate"><span class="pre">forward</span></code>. The hook can modify the
output. It can modify the input inplace but it will not have effect on
forward since this is called after <a class="reference internal" href="#e3ti.module.E3TIModule.forward" title="e3ti.module.E3TIModule.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called. The hook
should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>If <code class="docutils literal notranslate"><span class="pre">with_kwargs</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the forward hook will be passed the
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> given to the forward function and be expected to return the
output possibly modified. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hook</strong> (<em>Callable</em>) – The user defined hook to be registered.</p></li>
<li><p><strong>prepend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the provided <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired
before all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on this
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Otherwise, the provided
<code class="docutils literal notranslate"><span class="pre">hook</span></code> will be fired after all existing <code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks on
this <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.Module</span></code>. Note that global
<code class="docutils literal notranslate"><span class="pre">forward</span></code> hooks registered with
<code class="xref py py-func docutils literal notranslate"><span class="pre">register_module_forward_hook()</span></code> will fire before all hooks
registered by this method.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>with_kwargs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be passed the
kwargs given to the forward function.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>always_call</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code> the <code class="docutils literal notranslate"><span class="pre">hook</span></code> will be run regardless of
whether an exception is raised while calling the Module.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code> –     a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.hooks.RemovableHandle</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__call__">
<span class="sig-name descname"><span class="pre">__call__</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="p"><span class="pre">[</span></span><span class="pre">Ellipsis</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></em><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1732-L1736"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__call__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__setstate__">
<span class="sig-name descname"><span class="pre">__setstate__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1884-L1909"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__setstate__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__getattr__">
<span class="sig-name descname"><span class="pre">__getattr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1918-L1933"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__getattr__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__setattr__">
<span class="sig-name descname"><span class="pre">__setattr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L1935-L2032"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__setattr__" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>value</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>torch.Tensor</em></a><em>, </em><em>Module</em><em>]</em>)</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__delattr__">
<span class="sig-name descname"><span class="pre">__delattr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2034-L2043"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__delattr__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2064-L2086"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_state_dict_post_hook" title="Link to this definition"></a></dt>
<dd><p>Register a post-hook for the <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> method.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, state_dict, prefix, local_metadata) -&gt; None</p>
</dd>
</dl>
<p>The registered hooks can modify the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code> inplace.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2088-L2099"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_state_dict_pre_hook" title="Link to this definition"></a></dt>
<dd><p>Register a pre-hook for the <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> method.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, prefix, keep_vars) -&gt; None</p>
</dd>
</dl>
<p>The registered hooks can be used to perform pre-processing before the <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>
call is made.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.T_destination">
<span class="sig-name descname"><span class="pre">T_destination</span></span><a class="headerlink" href="#e3ti.module.E3TIModule.T_destination" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.state_dict">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">T_destination</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">...</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">...</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">T_destination</span></span></span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2145-L2232"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.state_dict" title="Link to this definition"></a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="keyword-only-separator o"><abbr title="Keyword-only parameters separator (PEP 3102)"><span class="pre">*</span></abbr></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">...</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keep_vars</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">...</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>Return a dictionary containing references to the whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.
Parameters and buffers set to <code class="docutils literal notranslate"><span class="pre">None</span></code> are not included.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The returned object is a shallow copy. It contains references
to the module’s parameters and buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">state_dict()</span></code> also accepts positional arguments for
<code class="docutils literal notranslate"><span class="pre">destination</span></code>, <code class="docutils literal notranslate"><span class="pre">prefix</span></code> and <code class="docutils literal notranslate"><span class="pre">keep_vars</span></code> in order. However,
this is being deprecated and keyword arguments will be enforced in
future releases.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Please avoid the use of argument <code class="docutils literal notranslate"><span class="pre">destination</span></code> as it is not
designed for end-users.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>destination</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>, </em><em>optional</em>) – If provided, the state of module will
be updated into the dict and the same object is returned.
Otherwise, an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code> will be created and returned.
Default: <code class="docutils literal notranslate"><span class="pre">None</span></code>.</p></li>
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>optional</em>) – a prefix added to parameter and buffer
names to compose the keys in state_dict. Default: <code class="docutils literal notranslate"><span class="pre">''</span></code>.</p></li>
<li><p><strong>keep_vars</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – by default the <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> s
returned in the state dict are detached from autograd. If it’s
set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, detaching will not be performed.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>dict</em> –     a dictionary containing a whole state of the module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_load_state_dict_pre_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_pre_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2254-L2264"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_load_state_dict_pre_hook" title="Link to this definition"></a></dt>
<dd><p>Register a pre-hook to be run before module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) -&gt; None  # noqa: B950</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>hook</strong> (<em>Callable</em>) – Callable hook that will be invoked before
loading the state dict.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.register_load_state_dict_post_hook">
<span class="sig-name descname"><span class="pre">register_load_state_dict_post_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hook</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2266-L2293"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.register_load_state_dict_post_hook" title="Link to this definition"></a></dt>
<dd><p>Register a post-hook to be run after module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code> is called.</p>
<dl class="simple">
<dt>It should have the following signature::</dt><dd><p>hook(module, incompatible_keys) -&gt; None</p>
</dd>
</dl>
<p>The <code class="docutils literal notranslate"><span class="pre">module</span></code> argument is the current module that this hook is registered
on, and the <code class="docutils literal notranslate"><span class="pre">incompatible_keys</span></code> argument is a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> consisting
of attributes <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>. <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code>
is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the missing keys and
<code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> is a <code class="docutils literal notranslate"><span class="pre">list</span></code> of <code class="docutils literal notranslate"><span class="pre">str</span></code> containing the unexpected keys.</p>
<p>The given incompatible_keys can be modified inplace if needed.</p>
<p>Note that the checks performed when calling <a class="reference internal" href="#e3ti.module.E3TIModule.load_state_dict" title="e3ti.module.E3TIModule.load_state_dict"><code class="xref py py-func docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> with
<code class="docutils literal notranslate"><span class="pre">strict=True</span></code> are affected by modifications the hook makes to
<code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> or <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code>, as expected. Additions to either
set of keys will result in an error being thrown when <code class="docutils literal notranslate"><span class="pre">strict=True</span></code>, and
clearing out both missing and unexpected keys will avoid an error.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code> –     a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">assign</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2476-L2589"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.load_state_dict" title="Link to this definition"></a></dt>
<dd><p>Copy parameters and buffers from <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this module and its descendants.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> function.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">assign</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code> the optimizer must be created after
the call to <a class="reference internal" href="#e3ti.module.E3TIModule.load_state_dict" title="e3ti.module.E3TIModule.load_state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">load_state_dict</span></code></a> unless
<a class="reference external" href="https://docs.pytorch.org/docs/stable/future_mod.html#torch.__future__.get_swap_module_params_on_conversion" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_swap_module_params_on_conversion()</span></code></a> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>assign</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – When <code class="docutils literal notranslate"><span class="pre">False</span></code>, the properties of the tensors
in the current module are preserved while when <code class="docutils literal notranslate"><span class="pre">True</span></code>, the
properties of the Tensors in the state dict are preserved. The only
exception is the <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> field of <code class="xref py py-class docutils literal notranslate">
<span class="pre">Default:</span> <span class="pre">``False`</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields –</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>missing_keys</strong> is a list of str containing any keys that are expected</dt><dd><p>by this module but missing from the provided <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>unexpected_keys</strong> is a list of str containing the keys that are not</dt><dd><p>expected by this module but present in the provided <code class="docutils literal notranslate"><span class="pre">state_dict</span></code>.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If a parameter or buffer is registered as <code class="docutils literal notranslate"><span class="pre">None</span></code> and its corresponding key
exists in <a class="reference internal" href="#e3ti.module.E3TIModule.state_dict" title="e3ti.module.E3TIModule.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a>, <a class="reference internal" href="#e3ti.module.E3TIModule.load_state_dict" title="e3ti.module.E3TIModule.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a> will raise a
<code class="docutils literal notranslate"><span class="pre">RuntimeError</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.parameters">
<span class="sig-name descname"><span class="pre">parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2611-L2634"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.parameters" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="(in PyTorch v2.8)">torch.nn.parameter.Parameter</a>]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.named_parameters">
<span class="sig-name descname"><span class="pre">named_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2636-L2666"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.named_parameters" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
<li><p><strong>remove_duplicate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to remove the duplicated
parameters in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>(str, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[Tuple[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter" title="(in PyTorch v2.8)">torch.nn.parameter.Parameter</a>]]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.buffers">
<span class="sig-name descname"><span class="pre">buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2668-L2689"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.buffers" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a>]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.Tensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.named_buffers">
<span class="sig-name descname"><span class="pre">named_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2691-L2720"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.named_buffers" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module. Defaults to True.</p></li>
<li><p><strong>remove_duplicate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to remove the duplicated buffers in the result. Defaults to True.</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>(str, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Iterator[Tuple[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)">torch.Tensor</a>]]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.children">
<span class="sig-name descname"><span class="pre">children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2722-L2729"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.children" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Iterator[Module]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.named_children">
<span class="sig-name descname"><span class="pre">named_children</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2731-L2749"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.named_children" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>(str, Module)</em> – Tuple containing a name and child module</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Iterator[Tuple[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a>, Module]]</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># xdoctest: +SKIP(&quot;undefined vars&quot;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.modules">
<span class="sig-name descname"><span class="pre">modules</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2751-L2776"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.modules" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Iterator[Module]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.named_modules">
<span class="sig-name descname"><span class="pre">named_modules</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">memo</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">remove_duplicate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2778-L2825"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.named_modules" title="Link to this definition"></a></dt>
<dd><p>Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>memo</strong> (<em>Optional</em><em>[</em><em>Set</em><em>[</em><em>Module</em><em>]</em><em>]</em>) – a memo to store the set of modules already added to the result</p></li>
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – a prefix that will be added to the name of the module</p></li>
<li><p><strong>remove_duplicate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – whether to remove the duplicated module instances in the result
or not</p></li>
</ul>
</dd>
<dt class="field-even">Yields<span class="colon">:</span></dt>
<dd class="field-even"><p><em>(str, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;-&gt;&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2827-L2847"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.train" title="Link to this definition"></a></dt>
<dd><p>Set the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.eval">
<span class="sig-name descname"><span class="pre">eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2849-L2865"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.eval" title="Link to this definition"></a></dt>
<dd><p>Set the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code></a>.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc" title="(in PyTorch v2.8)"><span>Locally disabling gradient computation</span></a> for a comparison between
<code class="xref any docutils literal notranslate"><span class="pre">.eval()</span></code> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Module</em> – self</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.requires_grad_">
<span class="sig-name descname"><span class="pre">requires_grad_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">requires_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2867-L2888"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.requires_grad_" title="Link to this definition"></a></dt>
<dd><p>Change if autograd should record operations on parameters in this module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc" title="(in PyTorch v2.8)"><span>Locally disabling gradient computation</span></a> for a comparison between
<code class="xref any docutils literal notranslate"><span class="pre">.requires_grad_()</span></code> and several similar mechanisms that may be confused with it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Module</em> – self</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.zero_grad">
<span class="sig-name descname"><span class="pre">zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">set_to_none</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2890-L2916"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.zero_grad" title="Link to this definition"></a></dt>
<dd><p>Reset gradients of all model parameters.</p>
<p>See similar function under <a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.optim.Optimizer</span></code></a> for more context.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>set_to_none</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – instead of setting to zero, set the grads to None.
See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.optim.Optimizer.zero_grad()</span></code></a> for details.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.share_memory">
<span class="sig-name descname"><span class="pre">share_memory</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2918-L2920"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.share_memory" title="Link to this definition"></a></dt>
<dd><p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.Tensor.share_memory_.html#torch.Tensor.share_memory_" title="(in PyTorch v2.8)"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.share_memory_()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>T</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2925-L2932"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.extra_repr" title="Link to this definition"></a></dt>
<dd><p>Set the extra representation of the module.</p>
<p>To print customized extra information, you should re-implement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)">str</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2934-L2957"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__repr__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.__dir__">
<span class="sig-name descname"><span class="pre">__dir__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2959-L2970"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.__dir__" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.compile">
<span class="sig-name descname"><span class="pre">compile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/torch/nn/modules/module.py#L2985-L2994"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.compile" title="Link to this definition"></a></dt>
<dd><p>Compile this Module’s forward using <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code></a>.</p>
<p>This Module’s <a class="reference internal" href="#e3ti.module.E3TIModule.__call__" title="e3ti.module.E3TIModule.__call__"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">__call__</span></code></a> method is compiled and all arguments are passed as-is
to <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code></a>.</p>
<p>See <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="(in PyTorch v2.8)"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.compile()</span></code></a> for details on the arguments for this function.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.save_hyperparameters">
<span class="sig-name descname"><span class="pre">save_hyperparameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/mixins/hparams_mixin.py#L51-L131"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.save_hyperparameters" title="Link to this definition"></a></dt>
<dd><p>Save arguments to <code class="docutils literal notranslate"><span class="pre">hparams</span></code> attribute.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Any</em>) – single object of <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref any docutils literal notranslate"><span class="pre">dict</span></code></a>, <a class="reference external" href="https://docs.python.org/3/glossary.html#term-namespace" title="(in Python v3.13)"><code class="xref any docutils literal notranslate"><span class="pre">NameSpace</span></code></a> or <code class="xref any docutils literal notranslate"><span class="pre">OmegaConf</span></code>
or string names or arguments from class <code class="docutils literal notranslate"><span class="pre">__init__</span></code></p></li>
<li><p><strong>ignore</strong> (<em>Optional</em><em>[</em><em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Sequence" title="(in Python v3.13)"><em>collections.abc.Sequence</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>]</em>) – an argument name or a list of argument names from
class <code class="docutils literal notranslate"><span class="pre">__init__</span></code> to be ignored</p></li>
<li><p><strong>frame</strong> (<em>Optional</em><em>[</em><em>types.FrameType</em><em>]</em>) – a frame object. Default is None</p></li>
<li><p><strong>logger</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>) – Whether to send the hyperparameters to the logger. Default: True</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<dl>
<dt>Example::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.core.mixins</span><span class="w"> </span><span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign arguments</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="s1">&#39;arg1&#39;</span><span class="p">,</span> <span class="s1">&#39;arg3&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.core.mixins</span><span class="w"> </span><span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">AutomaticArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># equivalent automatic</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">AutomaticArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg2&quot;: abc</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.core.mixins</span><span class="w"> </span><span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">SingleArgModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># manually assign single argument</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">SingleArgModel</span><span class="p">(</span><span class="n">Namespace</span><span class="p">(</span><span class="n">p1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p2</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="n">p3</span><span class="o">=</span><span class="mf">3.14</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;p1&quot;: 1</span>
<span class="go">&quot;p2&quot;: abc</span>
<span class="go">&quot;p3&quot;: 3.14</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">pytorch_lightning.core.mixins</span><span class="w"> </span><span class="kn">import</span> <span class="n">HyperparametersMixin</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span><span class="w"> </span><span class="nc">ManuallyArgsModel</span><span class="p">(</span><span class="n">HyperparametersMixin</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="c1"># pass argument(s) to ignore as a string or in a list</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">ignore</span><span class="o">=</span><span class="s1">&#39;arg2&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="gp">... </span>        <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ManuallyArgsModel</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;abc&#39;</span><span class="p">,</span> <span class="mf">3.14</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">hparams</span>
<span class="go">&quot;arg1&quot;: 1</span>
<span class="go">&quot;arg3&quot;: 3.14</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.hparams">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">lightning_fabric.utilities.data.AttributeDict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping" title="(in Python v3.13)"><span class="pre">collections.abc.MutableMapping</span></a></em><a class="headerlink" href="#e3ti.module.E3TIModule.hparams" title="Link to this definition"></a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#e3ti.module.E3TIModule.save_hyperparameters" title="e3ti.module.E3TIModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. It is mutable by the user. For
the frozen set of initial hyperparameters, use <a class="reference internal" href="#e3ti.module.E3TIModule.hparams_initial" title="e3ti.module.E3TIModule.hparams_initial"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams_initial</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Mutable hyperparameters dictionary</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Union[lightning_fabric.utilities.data.AttributeDict, <a class="reference external" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.MutableMapping" title="(in Python v3.13)">collections.abc.MutableMapping</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.hparams_initial">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">hparams_initial</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">lightning_fabric.utilities.data.AttributeDict</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.hparams_initial" title="Link to this definition"></a></dt>
<dd><p>The collection of hyperparameters saved with <a class="reference internal" href="#e3ti.module.E3TIModule.save_hyperparameters" title="e3ti.module.E3TIModule.save_hyperparameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">save_hyperparameters()</span></code></a>. These contents are read-only.
Manual updates to the saved hyperparameters can instead be performed through <a class="reference internal" href="#e3ti.module.E3TIModule.hparams" title="e3ti.module.E3TIModule.hparams"><code class="xref py py-attr docutils literal notranslate"><span class="pre">hparams</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>AttributeDict</em> – immutable initial hyperparameters</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>lightning_fabric.utilities.data.AttributeDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L30-L35"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_fit_start" title="Link to this definition"></a></dt>
<dd><p>Called at the very beginning of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L37-L42"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_fit_end" title="Link to this definition"></a></dt>
<dd><p>Called at the very end of fit.</p>
<p>If on DDP it is called on every process</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_train_start">
<span class="sig-name descname"><span class="pre">on_train_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L44-L45"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_train_start" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of training after sanity check.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_train_end">
<span class="sig-name descname"><span class="pre">on_train_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L47-L48"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_train_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of training before logger experiment is closed.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_start">
<span class="sig-name descname"><span class="pre">on_validation_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L50-L51"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_start" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_end">
<span class="sig-name descname"><span class="pre">on_validation_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L53-L54"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of validation.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_start">
<span class="sig-name descname"><span class="pre">on_test_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L56-L57"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_start" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_end">
<span class="sig-name descname"><span class="pre">on_test_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L59-L60"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of testing.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_start">
<span class="sig-name descname"><span class="pre">on_predict_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L62-L63"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_start" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_end">
<span class="sig-name descname"><span class="pre">on_predict_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L65-L66"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L68-L77"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_train_batch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the training loop before anything happens for that batch.</p>
<p>If you return -1 here, you will skip training for the rest of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>Optional[<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)">int</a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L79-L91"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_train_batch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the training loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>pytorch_lightning.utilities.types.STEP_OUTPUT</em>) – The outputs of training_step(x)</p></li>
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the training DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The value <code class="docutils literal notranslate"><span class="pre">outputs[&quot;loss&quot;]</span></code> here will be the normalized value w.r.t <code class="docutils literal notranslate"><span class="pre">accumulate_grad_batches</span></code> of the
loss returned from <code class="docutils literal notranslate"><span class="pre">training_step</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_batch_start">
<span class="sig-name descname"><span class="pre">on_validation_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L93-L101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_batch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the validation loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_batch_end">
<span class="sig-name descname"><span class="pre">on_validation_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L103-L114"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_batch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the validation loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>pytorch_lightning.utilities.types.STEP_OUTPUT</em>) – The outputs of validation_step(x)</p></li>
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the validation DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_batch_start">
<span class="sig-name descname"><span class="pre">on_test_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L116-L124"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_batch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the test loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_batch_end">
<span class="sig-name descname"><span class="pre">on_test_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L126-L135"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_batch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the test loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>pytorch_lightning.utilities.types.STEP_OUTPUT</em>) – The outputs of test_step(x)</p></li>
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_batch_start">
<span class="sig-name descname"><span class="pre">on_predict_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L137-L145"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_batch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the predict loop before anything happens for that batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the test DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_batch_end">
<span class="sig-name descname"><span class="pre">on_predict_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">outputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L147-L156"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_batch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the predict loop after the batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outputs</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – The outputs of predict_step(x)</p></li>
<li><p><strong>batch</strong> (<em>Any</em>) – The batched data as it is returned by the prediction DataLoader.</p></li>
<li><p><strong>batch_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the batch</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – the index of the dataloader</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_model_zero_grad">
<span class="sig-name descname"><span class="pre">on_validation_model_zero_grad</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L158-L160"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_model_zero_grad" title="Link to this definition"></a></dt>
<dd><p>Called by the training loop to release gradients before entering the validation loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_model_eval">
<span class="sig-name descname"><span class="pre">on_validation_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L162-L169"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_model_eval" title="Link to this definition"></a></dt>
<dd><p>Called when the validation loop starts.</p>
<p>The validation loop by default calls <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> on the LightningModule before it starts. Override this hook
to change the behavior. See also <code class="xref py py-meth docutils literal notranslate"><span class="pre">on_validation_model_train()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_model_train">
<span class="sig-name descname"><span class="pre">on_validation_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L171-L180"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_model_train" title="Link to this definition"></a></dt>
<dd><p>Called when the validation loop ends.</p>
<p>The validation loop by default restores the <a class="reference internal" href="#e3ti.module.E3TIModule.training" title="e3ti.module.E3TIModule.training"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">training</span></code></a> mode of the LightningModule to what it was before
starting validation. Override this hook to change the behavior. See also
<code class="xref py py-meth docutils literal notranslate"><span class="pre">on_validation_model_eval()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_model_eval">
<span class="sig-name descname"><span class="pre">on_test_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L182-L189"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_model_eval" title="Link to this definition"></a></dt>
<dd><p>Called when the test loop starts.</p>
<p>The test loop by default calls <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> on the LightningModule before it starts. Override this hook
to change the behavior. See also <code class="xref py py-meth docutils literal notranslate"><span class="pre">on_test_model_train()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_model_train">
<span class="sig-name descname"><span class="pre">on_test_model_train</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L191-L200"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_model_train" title="Link to this definition"></a></dt>
<dd><p>Called when the test loop ends.</p>
<p>The test loop by default restores the <a class="reference internal" href="#e3ti.module.E3TIModule.training" title="e3ti.module.E3TIModule.training"><code class="xref any py py-attr docutils literal notranslate"><span class="pre">training</span></code></a> mode of the LightningModule to what it was before
starting testing. Override this hook to change the behavior. See also
<code class="xref py py-meth docutils literal notranslate"><span class="pre">on_test_model_eval()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_model_eval">
<span class="sig-name descname"><span class="pre">on_predict_model_eval</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L202-L209"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_model_eval" title="Link to this definition"></a></dt>
<dd><p>Called when the predict loop starts.</p>
<p>The predict loop by default calls <code class="docutils literal notranslate"><span class="pre">.eval()</span></code> on the LightningModule before it starts. Override this hook
to change the behavior.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_train_epoch_start">
<span class="sig-name descname"><span class="pre">on_train_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L211-L212"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_train_epoch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the training loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L214-L239"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_train_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the training loop at the very end of the epoch.</p>
<p>To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
<code class="xref py py-class docutils literal notranslate"><span class="pre">LightningModule</span></code> and access them in this hook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MyLightningModule</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">...</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">on_train_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># do something with all training_step outputs, for example:</span>
        <span class="n">epoch_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="s2">&quot;training_epoch_mean&quot;</span><span class="p">,</span> <span class="n">epoch_mean</span><span class="p">)</span>
        <span class="c1"># free up the memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_step_outputs</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_epoch_start">
<span class="sig-name descname"><span class="pre">on_validation_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L241-L242"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_epoch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the validation loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_validation_epoch_end">
<span class="sig-name descname"><span class="pre">on_validation_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L244-L245"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_validation_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the validation loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_epoch_start">
<span class="sig-name descname"><span class="pre">on_test_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L247-L248"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_epoch_start" title="Link to this definition"></a></dt>
<dd><p>Called in the test loop at the very beginning of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_test_epoch_end">
<span class="sig-name descname"><span class="pre">on_test_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L250-L251"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_test_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Called in the test loop at the very end of the epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_epoch_start">
<span class="sig-name descname"><span class="pre">on_predict_epoch_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L253-L254"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_epoch_start" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_predict_epoch_end">
<span class="sig-name descname"><span class="pre">on_predict_epoch_end</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L256-L257"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_predict_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of predicting.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_before_zero_grad">
<span class="sig-name descname"><span class="pre">on_before_zero_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L259-L278"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_before_zero_grad" title="Link to this definition"></a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">training_step()</span></code> and before <code class="docutils literal notranslate"><span class="pre">optimizer.zero_grad()</span></code>.</p>
<p>Called in the training loop after taking an optimizer step and before zeroing grads.
Good place to inspect weight information with weights updated.</p>
<p>This is where it is called:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">optimizer</span> <span class="ow">in</span> <span class="n">optimizers</span><span class="p">:</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">training_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">on_before_zero_grad</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span> <span class="c1"># &lt; ---- called here</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a>) – The optimizer for which grads should be zeroed.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_before_backward">
<span class="sig-name descname"><span class="pre">on_before_backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L280-L287"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_before_backward" title="Link to this definition"></a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>loss</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>torch.Tensor</em></a>) – Loss divided by number of batches for gradient accumulation and scaled if using AMP.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_after_backward">
<span class="sig-name descname"><span class="pre">on_after_backward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L289-L296"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_after_backward" title="Link to this definition"></a></dt>
<dd><p>Called after <code class="docutils literal notranslate"><span class="pre">loss.backward()</span></code> and before optimizers are stepped.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If using native AMP, the gradients will not be unscaled at this point.
Use the <code class="docutils literal notranslate"><span class="pre">on_before_optimizer_step</span></code> if you need the unscaled gradients.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_before_optimizer_step">
<span class="sig-name descname"><span class="pre">on_before_optimizer_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L298-L323"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_before_optimizer_step" title="Link to this definition"></a></dt>
<dd><p>Called before <code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code>.</p>
<p>If using gradient accumulation, the hook is called once the gradients have been accumulated.
See: <a href="#id1"><span class="problematic" id="id2">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.accumulate_grad_batches`</span></a>.</p>
<p>If using AMP, the loss will be unscaled before calling this hook.
See these <a class="reference external" href="https://pytorch.org/docs/stable/notes/amp_examples.html#working-with-unscaled-gradients">docs</a>
for more information on the scaling of gradients.</p>
<p>If clipping gradients, the gradients will not have been clipped yet.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>optimizer</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/optim.html#torch.optim.Optimizer" title="(in PyTorch v2.8)"><em>torch.optim.optimizer.Optimizer</em></a>) – Current optimizer being used.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">on_before_optimizer_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
    <span class="c1"># example to inspect gradient information in tensorboard</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span> <span class="o">%</span> <span class="mi">25</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># don&#39;t make the tf file huge</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">add_histogram</span><span class="p">(</span>
                <span class="n">tag</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">global_step</span>
            <span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.configure_sharded_model">
<span class="sig-name descname"><span class="pre">configure_sharded_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L325-L330"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.configure_sharded_model" title="Link to this definition"></a></dt>
<dd><p>Deprecated.</p>
<p>Use <code class="xref py py-meth docutils literal notranslate"><span class="pre">configure_model()</span></code> instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.configure_model">
<span class="sig-name descname"><span class="pre">configure_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L332-L344"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.configure_model" title="Link to this definition"></a></dt>
<dd><p>Hook to create modules in a strategy and precision aware context.</p>
<p>This is particularly useful for when using sharded strategies (FSDP and DeepSpeed), where we’d like to shard
the model instantly to save memory and initialization time.
For non-sharded strategies, you can choose to override this hook or to initialize your model under the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">init_module()</span></code> context manager.</p>
<p>This hook is called during each of fit/val/test/predict stages in the same process, so ensure that
implementation of this hook is <strong>idempotent</strong>, i.e., after the first time the hook is called, subsequent calls
to it should be a no-op.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.prepare_data_per_node">
<span class="sig-name descname"><span class="pre">prepare_data_per_node</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.prepare_data_per_node" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.allow_zero_length_dataloader_with_multiple_devices">
<span class="sig-name descname"><span class="pre">allow_zero_length_dataloader_with_multiple_devices</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><span class="pre">bool</span></a></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#e3ti.module.E3TIModule.allow_zero_length_dataloader_with_multiple_devices" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L364-L418"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.prepare_data" title="Link to this definition"></a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>


<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L420-L445"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.setup" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>stage</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.teardown">
<span class="sig-name descname"><span class="pre">teardown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">stage</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L447-L453"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.teardown" title="Link to this definition"></a></dt>
<dd><p>Called at the end of fit (train + validate), validate, test, or predict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>stage</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>) – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L455-L482"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.train_dataloader" title="Link to this definition"></a></dt>
<dd><p>An iterable or collection of iterables specifying training samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id3"><span class="problematic" id="id4">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#e3ti.module.E3TIModule.setup" title="e3ti.module.E3TIModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.setup" title="e3ti.module.E3TIModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pytorch_lightning.utilities.types.TRAIN_DATALOADERS</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.test_dataloader">
<span class="sig-name descname"><span class="pre">test_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L484-L512"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.test_dataloader" title="Link to this definition"></a></dt>
<dd><p>An iterable or collection of iterables specifying test samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>For data processing use the following pattern:</p>
<blockquote>
<div><ul class="simple">
<li><p>download in <a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p>process and split in <a class="reference internal" href="#e3ti.module.E3TIModule.setup" title="e3ti.module.E3TIModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
</div></blockquote>
<p>However, the above are only necessary for distributed processing.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>do not assign state in prepare_data</p>
</div>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">test()</span></code></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.setup" title="e3ti.module.E3TIModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware.
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a test dataset and a <a class="reference internal" href="#e3ti.module.E3TIModule.test_step" title="e3ti.module.E3TIModule.test_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">test_step()</span></code></a>, you don’t need to implement
this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pytorch_lightning.utilities.types.EVAL_DATALOADERS</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.val_dataloader">
<span class="sig-name descname"><span class="pre">val_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L514-L539"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.val_dataloader" title="Link to this definition"></a></dt>
<dd><p>An iterable or collection of iterables specifying validation samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>The dataloader you return will not be reloaded unless you set
<a href="#id5"><span class="problematic" id="id6">:paramref:`~pytorch_lightning.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs`</span></a> to
a positive integer.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">validate()</span></code></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.setup" title="e3ti.module.E3TIModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you don’t need a validation dataset and a <a class="reference internal" href="#e3ti.module.E3TIModule.validation_step" title="e3ti.module.E3TIModule.validation_step"><code class="xref py py-meth docutils literal notranslate"><span class="pre">validation_step()</span></code></a>, you don’t need to
implement this method.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>pytorch_lightning.utilities.types.EVAL_DATALOADERS</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.predict_dataloader">
<span class="sig-name descname"><span class="pre">predict_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L541-L562"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.predict_dataloader" title="Link to this definition"></a></dt>
<dd><p>An iterable or collection of iterables specifying prediction samples.</p>
<p>For more information about multiple dataloaders, see this <span class="xref std std-ref">section</span>.</p>
<p>It’s recommended that all data downloads and preparation happen in <a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a>.</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.prepare_data" title="e3ti.module.E3TIModule.prepare_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">prepare_data()</span></code></a></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.setup" title="e3ti.module.E3TIModule.setup"><code class="xref py py-meth docutils literal notranslate"><span class="pre">setup()</span></code></a></p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning tries to add the correct sampler for distributed and arbitrary hardware
There is no need to set it yourself.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A <a class="reference external" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code></a> or a sequence of them specifying prediction samples.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>pytorch_lightning.utilities.types.EVAL_DATALOADERS</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L564-L611"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.transfer_batch_to_device" title="Link to this definition"></a></dt>
<dd><p>Override this hook if your <a class="reference external" href="https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code></a> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a> or anything that implements <code class="xref any docutils literal notranslate"><span class="pre">.to(...)</span></code></p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a></p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a></p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensor_attributes.html#torch.device" title="(in PyTorch v2.8)"><em>torch.device</em></a>) – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A reference to the data on the new device.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_before_batch_transfer">
<span class="sig-name descname"><span class="pre">on_before_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L613-L639"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_before_batch_transfer" title="Link to this definition"></a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch before it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A batch of data</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">on_before_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.on_after_batch_transfer" title="e3ti.module.E3TIModule.on_after_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_after_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.transfer_batch_to_device" title="e3ti.module.E3TIModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_after_batch_transfer">
<span class="sig-name descname"><span class="pre">on_after_batch_transfer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_idx</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L641-L667"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_after_batch_transfer" title="Link to this definition"></a></dt>
<dd><p>Override to alter or apply batch augmentations to your batch after it is transferred to the device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> (<em>Any</em>) – A batch of data that needs to be altered or augmented.</p></li>
<li><p><strong>dataloader_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>) – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A batch of data</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">on_after_batch_transfer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gpu_transforms</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.on_before_batch_transfer" title="e3ti.module.E3TIModule.on_before_batch_transfer"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_before_batch_transfer()</span></code></a></p></li>
<li><p><a class="reference internal" href="#e3ti.module.E3TIModule.transfer_batch_to_device" title="e3ti.module.E3TIModule.transfer_batch_to_device"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transfer_batch_to_device()</span></code></a></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_load_checkpoint">
<span class="sig-name descname"><span class="pre">on_load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L673-L690"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_load_checkpoint" title="Link to this definition"></a></dt>
<dd><p>Called by Lightning to restore your model. If you saved something with <a class="reference internal" href="#e3ti.module.E3TIModule.on_save_checkpoint" title="e3ti.module.E3TIModule.on_save_checkpoint"><code class="xref py py-meth docutils literal notranslate"><span class="pre">on_save_checkpoint()</span></code></a> this is
your chance to restore this.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – Loaded checkpoint</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">on_load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of the time you don&#39;t need to implement this method</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">something_cool_i_want_to_save</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning auto-restores global step, epoch, and train state including amp scaling.
There is no need for you to restore anything regarding training.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="e3ti.module.E3TIModule.on_save_checkpoint">
<span class="sig-name descname"><span class="pre">on_save_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/winstonwinstonwinston/E3TI/blob/0.1.0/../micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/core/hooks.py#L692-L711"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#e3ti.module.E3TIModule.on_save_checkpoint" title="Link to this definition"></a></dt>
<dd><p>Called by Lightning when saving a checkpoint to give you a chance to store anything else you might want to
save.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>checkpoint</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – The full checkpoint dictionary before it gets dumped to a file.
Implementations of this hook can insert additional data into this dictionary.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">on_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">):</span>
    <span class="c1"># 99% of use cases you don&#39;t need to implement this method</span>
    <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;something_cool_i_want_to_save&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_cool_pickable_object</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Lightning saves all aspects of training (epoch, global step, etc…)
including amp scaling.
There is no need for you to store anything about training.</p>
</div>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>