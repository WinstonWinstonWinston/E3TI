{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ad290f-6a0d-4f47-9d84-15bfa3697454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔═══════════════════════════════════════════════════╗\n",
      "║                                                   ║\n",
      "║  ██████╗   ██████╗    ██╗      ██████╗   ██╗  ██╗ ║\n",
      "║ ██╔════╝  ██╔══██╗   ██╔██╗    ██╔══██╗  ██║ ██╔╝ ║\n",
      "║ ╚█████╗   ██████╔╝  ██╔╝╚██╗   ██████╔╝  █████╔╝  ║\n",
      "║  ╚═══██╗  ██╔═══╝  ██╔╝  ╚██╗  ██╔══██╗  ██╔═██╗  ║\n",
      "║ ██████╔╝  ██║     ██╔╝    ╚██╗ ██║  ██║  ██║ ╚██╗ ║\n",
      "║ ╚═════╝   ╚═╝     ╚═╝      ╚═╝ ╚═╝  ╚═╝  ╚═╝  ╚═╝ ║\n",
      "║                                                   ║\n",
      "║     Statistical Physics Autodiff Research Kit     ║\n",
      "╚═══════════════════════════════════════════════════╝\n",
      "\n",
      "          V(r)           ψ, φ              q\n",
      "           │               │               │\n",
      "           ○               ○               ○\n",
      "         ╱ | ╲           ╱ | ╲           ╱ | ╲\n",
      "        ○  ○  ○         ○  ○  ○         ○  ○  ○\n",
      "         ╲ | ╱           ╲ | ╱           ╲ | ╱\n",
      "           ○               ○               ○\n",
      "           │               │               │\n",
      "          g(r)             F              E(q)\n",
      "\n",
      "It’s in the canonical ensemble. Ish.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ITO_DDPM import *\n",
    "from architechtures.PaiNN_Like import *\n",
    "from architechtures.embeddings import *\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.curdir)\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"../SPARK/\"))\n",
    "sys.path.append(parent_dir)\n",
    "from utils import *\n",
    "device = \"cuda\"\n",
    "from torch.serialization import add_safe_globals\n",
    "\n",
    "add_safe_globals([ImplicitTransferOperatorDDPM])\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "\n",
    "# Crash on NaNs/Infs\n",
    "torch._C._set_warnAlways(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a32f84-5957-4a73-b246-655459bbb341",
   "metadata": {},
   "source": [
    "## load in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0482403e-0c81-4009-a02f-e91d9b0682cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 16357 / 16384 trajectories.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"datasets/AlanaineDipeptideVacuum/\"\n",
    "base_path = f\"{data_path}ADP_Vacuum\"\n",
    "pos_path = base_path + \"_position\"\n",
    "mom_path = base_path + \"_momentum\"\n",
    "\n",
    "position_data = torch.load(pos_path, map_location=device)\n",
    "momentum_data = torch.load(mom_path, map_location=device)\n",
    "\n",
    "# Check for NaNs or Infs in position and momentum data\n",
    "bad_pos = ~torch.isfinite(position_data).all(dim=(0, 2, 3))  # shape: (16384,)\n",
    "bad_mom = ~torch.isfinite(momentum_data).all(dim=(0, 2, 3))  # shape: (16384,)\n",
    "\n",
    "# Combine masks and negate to get valid ones\n",
    "valid_mask = ~(bad_pos | bad_mom)\n",
    "\n",
    "# Filter both tensors\n",
    "position_data = position_data[:, valid_mask, :, :]\n",
    "momentum_data = momentum_data[:, valid_mask, :, :]\n",
    "\n",
    "print(f\"Kept {valid_mask.sum().item()} / {valid_mask.shape[0]} trajectories.\")\n",
    "\n",
    "top, node_features, mass, energy_dict = build_top_and_features(\"datasets/AlanaineDipeptideVacuum/alanine-dipeptide.prmtop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fa107-2810-4387-a746-61856631c22d",
   "metadata": {},
   "source": [
    "## create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed66ad5c-a311-421a-a548-6311a30344c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load full model object...\n",
      "Loaded model with 126,496 parameters.\n"
     ]
    }
   ],
   "source": [
    "# Noise Schedule Settings\n",
    "low = -8.0\n",
    "high = -4.0\n",
    "diffusion_steps = 1000\n",
    "noise_schedule = SigmoidNoiseSchedule(low, high, diffusion_steps, device)\n",
    "t_diff_max = diffusion_steps\n",
    "s_phys_max = 198\n",
    "\n",
    "# Architecture Settings\n",
    "C_x = 2\n",
    "C_v_i = 1\n",
    "C_z_i = 2\n",
    "C = 64\n",
    "C_v = C\n",
    "C_z = C\n",
    "C_t = C\n",
    "C_s = C\n",
    "N = 22\n",
    "B = 16\n",
    "\n",
    "f_0_layers = [C_s + C_t + C_v + C_z_i, C_s + C_t + C_v + C_z_i, C_z]\n",
    "f_1_layers = [C_x + C_z, C_x + C_z, C_x]\n",
    "f_2_layers = [C_x + C_z, C_x + C_z, C_v]\n",
    "f_3_layers = [C_x + C_z, C_x + C_z, C_z]\n",
    "f_4_layers = [C_v + C_z, C_v + C_z, C_v]\n",
    "f_5_layers = [C_v + C_z, C_v + C_z, C_z]\n",
    "\n",
    "W_1_layers = [(2 * C_x + C_v_i, 3), (C_v, 3)]\n",
    "W_2_layers = [(C_x, 3), (C_v, 3)]\n",
    "W_3_layers = [(C_v, 3), (C_v, 3)]\n",
    "W_4_layers = [(C_v, 3), (C_x, 3)]\n",
    "\n",
    "message_passing_steps = 3\n",
    "p = 0\n",
    "activation_function = nn.Tanh()\n",
    "\n",
    "t_diff_embedding = SinCosTimeEmbedding(C_t, max_t=t_diff_max, init_scale=1.0, learnable_scale=True, device=device)\n",
    "s_phys_embedding = SinCosTimeEmbedding(C_s, max_t=s_phys_max, init_scale=1.0, learnable_scale=True, device=device)\n",
    "\n",
    "EGNN = EquivariantGraphNeuralNetwork(\n",
    "    f_0_layers, f_1_layers, f_2_layers, f_3_layers, f_4_layers, f_5_layers,\n",
    "    W_1_layers, W_2_layers, W_3_layers, W_4_layers,\n",
    "    message_passing_steps, p, activation_function,\n",
    "    t_diff_embedding, s_phys_embedding,\n",
    "    device\n",
    ").to(device)\n",
    "\n",
    "DDPM = ImplicitTransferOperatorDDPM(\n",
    "    EGNN,\n",
    "    noise_schedule,\n",
    "    t_diff_max,\n",
    "    s_phys_max,\n",
    "    device\n",
    ").to(device)\n",
    "\n",
    "# Try loading full model first, fall back to state_dict\n",
    "try:\n",
    "    print(\"Trying to load full model object...\")\n",
    "    DDPM = torch.load(\"16_model_131072.pth\", map_location=device, weights_only=False)\n",
    "    DDPM.eval()\n",
    "    print(f\"Loaded model with {sum(p.numel() for p in DDPM.parameters() if p.requires_grad):,} parameters.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load model\")\n",
    "    print(f\"Created model with {sum(p.numel() for p in DDPM.parameters() if p.requires_grad):,} parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf092a-a3ae-4ab9-a952-9d2a99d747f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = t_diff_embedding.plot_embedding()\n",
    "plot = s_phys_embedding.plot_embedding()\n",
    "plot = noise_schedule.plot(\"Noise Schedule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae35926-bd6f-457d-b6ce-141a833d64e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s_t = [position_data[199,:B],momentum_data[199,:B]]\n",
    "x_0_0 = [position_data[0,:B],momentum_data[0,:B]]\n",
    "v_0_0 = [torch.zeros_like(x_0_0[0],device=device)]\n",
    "z_0_0 = [mass.unsqueeze(dim=0).expand(B,22), node_features['charge'].unsqueeze(dim=0).expand(B,22)]\n",
    "\n",
    "out = DDPM(x_s_t, x_0_0, v_0_0, z_0_0, 200*torch.zeros(B,device=device,dtype=torch.int), 200*torch.ones(B,device=device,dtype=torch.int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7b496-c73c-45cb-9616-a2396120dce2",
   "metadata": {},
   "source": [
    "## test equivariance using commutator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d283020-474d-4c72-aed7-1a4c49d2d56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean relative error in momentum over 20 rotations: 2.36e-07\n",
      "mean relative error in position over 20 rotations: 4.75e-07\n",
      "\n",
      "Median momentum RMSD averaged over 20 rotations: 0.000001\n",
      "Median position RMSD difference averaged over 20 rotations: 0.000000\n",
      "\n",
      "Mean momentum RMSD averaged over 20 rotations: 0.000002\n",
      "Mean position RMSD difference averaged over 20 rotations: 0.000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_iters = 20\n",
    "\n",
    "median_total_mom_error = []\n",
    "median_total_pos_error = []\n",
    "\n",
    "mean_total_mom_error = []\n",
    "mean_total_pos_error = []\n",
    "\n",
    "eps_mom = 0.0\n",
    "eps_pos = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_iters):\n",
    "        # Rotate position and momentum for x_s_t\n",
    "        R = None\n",
    "        RP, R, _ = random_rotation_3d(position_data[199,:B])  # rotate pos\n",
    "        RM, _, _ = random_rotation_3d(momentum_data[199,:B], R)  # same R\n",
    "\n",
    "        # rotate x_0_0\n",
    "        R0P, _, _ = random_rotation_3d(position_data[0,:B], R)\n",
    "        R0M, _, _ = random_rotation_3d(momentum_data[0,:B], R)\n",
    "\n",
    "        # rotate v_0_0 (zeros)\n",
    "        Rv0 = torch.zeros_like(R0P, device=device)\n",
    "\n",
    "        # rotate scalar features\n",
    "        z_mass = mass.unsqueeze(0).expand(B, 22)  # [B, N]\n",
    "        z_charge = node_features['charge'].unsqueeze(0).expand(B, 22)  # [B, N]\n",
    "\n",
    "        # build rotated inputs\n",
    "        x_s_t_rot = [RP, RM]\n",
    "        x_0_0_rot = [R0P, R0M]\n",
    "        v_0_0_rot = [Rv0]\n",
    "        z_0_0_rot = [z_mass, z_charge]\n",
    "\n",
    "        # unrotated inputs\n",
    "        x_s_t = [position_data[199,:B], momentum_data[199,:B]]\n",
    "        x_0_0 = [position_data[0,:B], momentum_data[0,:B]]\n",
    "        v_0_0 = [torch.zeros_like(position_data[0,:B], device=device)]\n",
    "        z_0_0 = [z_mass, z_charge]\n",
    "\n",
    "        t_diff = 200 * torch.zeros(B, device=position_data[0].device,dtype=torch.int)\n",
    "        s_phys = 200 * torch.ones(B, device=position_data[0].device,dtype=torch.int)\n",
    "\n",
    "        # evaluate model\n",
    "        out_rot = DDPM(x_s_t_rot, x_0_0_rot, v_0_0_rot, z_0_0_rot, t_diff, s_phys)\n",
    "        out_ref = DDPM(x_s_t, x_0_0, v_0_0, z_0_0, t_diff, s_phys)\n",
    "        \n",
    "        mom_rot = out_rot[0]  # [B, N, 3]\n",
    "        pos_rot = out_rot[1]  # [B, N, 3]\n",
    "        \n",
    "        mom_ref = out_ref[0]\n",
    "        pos_ref = out_ref[1]\n",
    "\n",
    "        # rotate reference outputs\n",
    "        Rmom_ref, _, _ = random_rotation_3d(mom_ref, R)\n",
    "        Rpos_ref, _, _ = random_rotation_3d(pos_ref, R)\n",
    "\n",
    "\n",
    "        # RMSD\n",
    "        median_total_mom_error.append(torch.median((mom_rot - Rmom_ref)**2).sqrt().item())\n",
    "        median_total_pos_error.append(torch.median((pos_rot - Rpos_ref)**2).sqrt().item())\n",
    "\n",
    "        mean_total_mom_error.append(torch.mean((mom_rot - Rmom_ref)**2).sqrt().item())\n",
    "        mean_total_pos_error.append(torch.mean((pos_rot - Rpos_ref)**2).sqrt().item())\n",
    "\n",
    "        # relative error\n",
    "        eps_mom += torch.linalg.vector_norm(mom_rot - Rmom_ref) / (\n",
    "                   torch.linalg.vector_norm(mom_ref) + 1e-12)\n",
    "        eps_pos += torch.linalg.vector_norm(pos_rot - Rpos_ref) / (\n",
    "                   torch.linalg.vector_norm(pos_ref) + 1e-12)\n",
    "\n",
    "    eps_mom /= num_iters\n",
    "    eps_pos /= num_iters\n",
    "\n",
    "    print(f\"mean relative error in momentum over {num_iters} rotations: {eps_mom:.2e}\")\n",
    "    print(f\"mean relative error in position over {num_iters} rotations: {eps_pos:.2e}\\n\")\n",
    "\n",
    "    print(f\"Median momentum RMSD averaged over {num_iters} rotations: {sum(median_total_mom_error) / num_iters:.6f}\")\n",
    "    print(f\"Median position RMSD difference averaged over {num_iters} rotations: {sum(median_total_pos_error) / num_iters:.6f}\\n\")\n",
    "\n",
    "    print(f\"Mean momentum RMSD averaged over {num_iters} rotations: {sum(mean_total_mom_error) / num_iters:.6f}\")\n",
    "    print(f\"Mean position RMSD difference averaged over {num_iters} rotations: {sum(mean_total_pos_error) / num_iters:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60741e66-528a-4e6d-84bf-b6d0ab60192f",
   "metadata": {},
   "source": [
    "## look at the forward trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd64ee90-8f94-49b3-8bef-5353a55b7349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot trajectory evolution for positions and momentum\n",
    "@torch.no_grad()\n",
    "def plot_trajectories(tensor, title):\n",
    "    T, B, N, D = tensor.shape\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for k in range(B):\n",
    "        for j in range(N):\n",
    "            for i in range(D):\n",
    "                ax.plot(tensor[:, k, j, i].detach().cpu(), alpha=0.4, linewidth=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Diffusion Step t\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot histogram vs standard normal\n",
    "@torch.no_grad()\n",
    "def plot_hist_vs_normal(data_tensor, title):\n",
    "    data = data_tensor.flatten().detach().cpu()\n",
    "    x = torch.linspace(-5, 5, 500)\n",
    "    normal_pdf = torch.exp(-0.5 * x**2) / torch.sqrt(torch.tensor(2 * torch.pi))\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.hist(data, bins=100, density=True, alpha=0.6, label=\"model output over all batches, atoms, dims\")\n",
    "    plt.plot(x.numpy(), normal_pdf.numpy(), 'k--', linewidth=2, label=\"standard normal $\\mathcal{N}(0,1)$\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Value\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3724d775-e93b-4ccd-a9e9-94aa4e2cb7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Sample the trajectory\n",
    "# forward = DDPM.sample_forward_trajectory(x_s_t)\n",
    "\n",
    "# plot_trajectories(forward[0], \"Position Trajectories\")\n",
    "# plot_trajectories(forward[1], \"Momentum Trajectories\")\n",
    "\n",
    "# plot_hist_vs_normal(forward[0][-1], \"Position Forward Output vs Standard Normal\")\n",
    "# plot_hist_vs_normal(forward[1][-1], \"Momentum Forward Output vs Standard Normal\")\n",
    "\n",
    "# del forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365aa75e-2ad9-4f5d-9157-68143239faeb",
   "metadata": {},
   "source": [
    "## look at the reverse trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eaf4273-8137-4d8c-a5ab-dca244b62b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample the trajectory\n",
    "# reverse = DDPM.sample_reverse_trajectory(x_0_0, v_0_0, z_0_0, s_phys)\n",
    "\n",
    "# plot_trajectories(reverse[0], \"Position Trajectories\")\n",
    "# plot_trajectories(reverse[1], \"Momentum Trajectories\")\n",
    "\n",
    "# plot_hist_vs_normal(reverse[0][0], \"Position Reverse Output vs Standard Normal\")\n",
    "# plot_hist_vs_normal(reverse[1][0], \"Momentum Reverse Output vs Standard Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562e0af7-cfa6-4ca1-97b1-0aff3a35f073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Sample the trajectory\n",
    "# reverse_marginal = DDPM.sample_reverse_marginal(x_0_0, v_0_0, z_0_0, t_diff_max, s_phys)\n",
    "\n",
    "# plot_hist_vs_normal(reverse_marginal[0], \"Position Forward Output vs Standard Normal\")\n",
    "# plot_hist_vs_normal(reverse_marginal[1], \"Momentum Forward Output vs Standard Normal\")\n",
    "\n",
    "# del reverse_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f9e08d-cc29-455b-b5ad-a0d6c504e884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Sample the trajectory\n",
    "# reverse_marginal = DDPM.sample_reverse_marginal(x_0_0, v_0_0, z_0_0, 0,s_phys)\n",
    "\n",
    "# plot_hist_vs_normal(reverse_marginal[0], \"Position Forward Output vs Standard Normal\")\n",
    "# plot_hist_vs_normal(reverse_marginal[1], \"Momentum Forward Output vs Standard Normal\")\n",
    "\n",
    "# del reverse_marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "639447b6-68f1-4183-a9f0-6a78804356d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset():\n",
    "    \"\"\"\n",
    "    Dataset class for trajectories with randomly selected initial conditions (IC).\n",
    "\n",
    "    Args:\n",
    "        trajectory (Tensor): Tensor of trajectories with shape [trajectory index, time, features].\n",
    "        t_diff_max (int): Maximum diffusion time step.\n",
    "        s_phys_max (int): Maximum physical time for sampling.\n",
    "        device (str): Device to place tensors on (default: 'cpu').\n",
    "        seed (int, optional): Seed for random number generation.\n",
    "    \"\"\"\n",
    "    def __init__(self, trajectory, t_diff_max, s_phys_max, device,  seed=None):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.s_phys_max = s_phys_max\n",
    "        self.t_diff_max = t_diff_max\n",
    "        self.trajectory = trajectory\n",
    "\n",
    "        self.num_trajs = len(self.trajectory[0])\n",
    "        self.data_dim = len(self.trajectory[0,0])\n",
    "\n",
    "    def getitems(self, batch_size):\n",
    "        traj_idxs = torch.randint(0, self.num_trajs, (batch_size,),device=self.device)\n",
    "        \n",
    "        N_vals = torch.rand(batch_size,device=self.device)  * np.log(self.s_phys_max)\n",
    "        ic_idx = torch.randint(1, len(self.trajectory)- (self.s_phys_max), (batch_size,),device=self.device)\n",
    "        \n",
    "        s_phys = torch.floor(torch.exp(N_vals)).long()\n",
    "        t_diff = torch.randint(0, self.t_diff_max, (batch_size,),device=self.device)\n",
    "        x_0_0 = self.trajectory[ic_idx, traj_idxs]\n",
    "        x_s_0 = self.trajectory[ic_idx + s_phys, traj_idxs]\n",
    "        \n",
    "        return {\"x_0_0\":x_0_0,\n",
    "                \"x_s_0\":x_s_0,\n",
    "                \"t_diff\":t_diff,\n",
    "                \"s_phys\":s_phys}\n",
    "\n",
    "    def getitem(self):\n",
    "        return self.getitems(1)\n",
    "         \n",
    "dataset = TrajectoryDataset(torch.cat([position_data,momentum_data],dim=-1),t_diff_max,s_phys_max,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cac9c1-8383-4a1e-b49c-ff0972e5326a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwinsaton\u001b[0m (\u001b[33mwinsaton-univeristy-of-minnesota\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/users/1/sull1276/aced-ADP/wandb/run-20250530_195623-gxor819q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/winsaton-univeristy-of-minnesota/diffusion-training/runs/gxor819q' target=\"_blank\">BatchSize128</a></strong> to <a href='https://wandb.ai/winsaton-univeristy-of-minnesota/diffusion-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/winsaton-univeristy-of-minnesota/diffusion-training' target=\"_blank\">https://wandb.ai/winsaton-univeristy-of-minnesota/diffusion-training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/winsaton-univeristy-of-minnesota/diffusion-training/runs/gxor819q' target=\"_blank\">https://wandb.ai/winsaton-univeristy-of-minnesota/diffusion-training/runs/gxor819q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/256: 100%|█| 2048/2048 [06:38<00:00,  5.14 batch/s, batch=2047/2048, loss=0.991295, mom=6.0242e-01, pos=3.8887e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.991295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/256: 100%|█| 2048/2048 [05:43<00:00,  5.96 batch/s, batch=2047/2048, loss=0.901332, mom=5.9850e-01, pos=3.0283e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.901332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/256: 100%|█| 2048/2048 [05:30<00:00,  6.19 batch/s, batch=2047/2048, loss=0.842096, mom=5.8915e-01, pos=2.5294e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.842096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/256: 100%|█| 2048/2048 [06:16<00:00,  5.44 batch/s, batch=2047/2048, loss=0.871123, mom=6.2965e-01, pos=2.4147e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.871123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/256: 100%|█| 2048/2048 [06:26<00:00,  5.29 batch/s, batch=2047/2048, loss=0.839638, mom=6.2054e-01, pos=2.1910e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.839638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/256: 100%|█| 2048/2048 [06:28<00:00,  5.27 batch/s, batch=2047/2048, loss=0.815513, mom=5.9017e-01, pos=2.2535e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.815513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/256: 100%|█| 2048/2048 [06:32<00:00,  5.22 batch/s, batch=2047/2048, loss=0.920225, mom=6.9468e-01, pos=2.2554e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.920225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/256: 100%|█| 2048/2048 [06:40<00:00,  5.11 batch/s, batch=2047/2048, loss=0.818383, mom=6.1344e-01, pos=2.0494e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.818383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/256: 100%|█| 2048/2048 [06:14<00:00,  5.47 batch/s, batch=2047/2048, loss=0.818216, mom=6.1916e-01, pos=1.9905e-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.818216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/256: 100%|█| 2048/2048 [06:23<00:00,  5.35 batch/s, batch=2047/2048, loss=0.801980, mom=6.1044e-01, pos=1.9154e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.801980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/256: 100%|█| 2048/2048 [06:35<00:00,  5.18 batch/s, batch=2047/2048, loss=0.770520, mom=5.9363e-01, pos=1.7689e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss = 0.770520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/256: 100%|█| 2048/2048 [06:52<00:00,  4.97 batch/s, batch=2047/2048, loss=0.721888, mom=5.4026e-01, pos=1.8163e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss = 0.721888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/256: 100%|█| 2048/2048 [06:11<00:00,  5.51 batch/s, batch=2047/2048, loss=0.786725, mom=6.0138e-01, pos=1.8534e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss = 0.786725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/256: 100%|█| 2048/2048 [06:29<00:00,  5.26 batch/s, batch=2047/2048, loss=0.721418, mom=5.4258e-01, pos=1.7884e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss = 0.721418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/256: 100%|█| 2048/2048 [06:49<00:00,  5.00 batch/s, batch=2047/2048, loss=0.757624, mom=5.6446e-01, pos=1.9317e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss = 0.757624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/256: 100%|█| 2048/2048 [06:02<00:00,  5.65 batch/s, batch=2047/2048, loss=0.706580, mom=5.2428e-01, pos=1.8230e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss = 0.706580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/256: 100%|█| 2048/2048 [06:22<00:00,  5.36 batch/s, batch=2047/2048, loss=0.689454, mom=5.0828e-01, pos=1.8117e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss = 0.689454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/256: 100%|█| 2048/2048 [06:10<00:00,  5.53 batch/s, batch=2047/2048, loss=0.632324, mom=4.5555e-01, pos=1.7677e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss = 0.632324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/256: 100%|█| 2048/2048 [06:18<00:00,  5.41 batch/s, batch=2047/2048, loss=0.686475, mom=4.9998e-01, pos=1.8650e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss = 0.686475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/256: 100%|█| 2048/2048 [06:09<00:00,  5.54 batch/s, batch=2047/2048, loss=0.622894, mom=4.5033e-01, pos=1.7256e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss = 0.622894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/256: 100%|█| 2048/2048 [06:52<00:00,  4.97 batch/s, batch=2047/2048, loss=0.639012, mom=4.5863e-01, pos=1.8038e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Loss = 0.639012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/256: 100%|█| 2048/2048 [06:00<00:00,  5.69 batch/s, batch=2047/2048, loss=0.592325, mom=4.2676e-01, pos=1.6557e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss = 0.592325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/256: 100%|█| 2048/2048 [05:26<00:00,  6.27 batch/s, batch=2047/2048, loss=0.609420, mom=4.3397e-01, pos=1.7545e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Loss = 0.609420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/256: 100%|█| 2048/2048 [06:02<00:00,  5.66 batch/s, batch=2047/2048, loss=0.609993, mom=4.2911e-01, pos=1.8089e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Loss = 0.609993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/256: 100%|█| 2048/2048 [05:56<00:00,  5.74 batch/s, batch=2047/2048, loss=0.573210, mom=4.0139e-01, pos=1.7182e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss = 0.573210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/256: 100%|█| 2048/2048 [06:28<00:00,  5.28 batch/s, batch=2047/2048, loss=0.647055, mom=4.4064e-01, pos=2.0642e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Loss = 0.647055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/256: 100%|█| 2048/2048 [06:29<00:00,  5.26 batch/s, batch=2047/2048, loss=0.587018, mom=4.0981e-01, pos=1.7720e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Loss = 0.587018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/256: 100%|█| 2048/2048 [06:54<00:00,  4.94 batch/s, batch=2047/2048, loss=0.604233, mom=4.3291e-01, pos=1.7132e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Loss = 0.604233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/256: 100%|█| 2048/2048 [06:42<00:00,  5.08 batch/s, batch=2047/2048, loss=0.542936, mom=3.7916e-01, pos=1.6378e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Loss = 0.542936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/256: 100%|█| 2048/2048 [06:40<00:00,  5.11 batch/s, batch=2047/2048, loss=0.579766, mom=3.9366e-01, pos=1.8611e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss = 0.579766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/256: 100%|█| 2048/2048 [06:15<00:00,  5.45 batch/s, batch=2047/2048, loss=0.606727, mom=4.2253e-01, pos=1.8420e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Loss = 0.606727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/256: 100%|█| 2048/2048 [06:14<00:00,  5.46 batch/s, batch=2047/2048, loss=0.548153, mom=3.7711e-01, pos=1.7104e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Loss = 0.548153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/256: 100%|█| 2048/2048 [05:41<00:00,  6.00 batch/s, batch=2047/2048, loss=0.581435, mom=4.0264e-01, pos=1.7880e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Loss = 0.581435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/256: 100%|█| 2048/2048 [06:39<00:00,  5.13 batch/s, batch=2047/2048, loss=0.534961, mom=3.6387e-01, pos=1.7110e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Loss = 0.534961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/256: 100%|█| 2048/2048 [06:43<00:00,  5.07 batch/s, batch=2047/2048, loss=0.542177, mom=3.7790e-01, pos=1.6428e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Loss = 0.542177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/256: 100%|█| 2048/2048 [06:29<00:00,  5.26 batch/s, batch=2047/2048, loss=0.541108, mom=3.6755e-01, pos=1.7356e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Loss = 0.541108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/256: 100%|█| 2048/2048 [06:18<00:00,  5.41 batch/s, batch=2047/2048, loss=0.573176, mom=3.9088e-01, pos=1.8230e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Loss = 0.573176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/256:  33%|▎| 683/2048 [01:42<03:25,  6.65 batch/s, batch=683/2048, loss=0.544996, mom=3.7306e-01, pos=1.7193e-0"
     ]
    }
   ],
   "source": [
    "wandb_step = 0\n",
    "log_interval = 16\n",
    "plot_interval = 2048\n",
    "save_interval = 16*2048\n",
    "grad_clipping = 0\n",
    "name = f\"BatchSize{B}\"\n",
    "checkpoint_path = \"models/\"\n",
    "\n",
    "wandb.init(project=\"diffusion-training\", name=name)\n",
    "\n",
    "optimizer = optim.Adam(DDPM.parameters(),\n",
    "                       lr = 1e-3,\n",
    "                       betas = (0.9, 0.999),\n",
    "                       eps = 1e-8, \n",
    "                       weight_decay = 0.0,\n",
    "                       amsgrad = False)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99999)\n",
    "\n",
    "epochs = 256\n",
    "epoch_size = 2048*B \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    loader = tqdm(range(0, epoch_size, B), desc=f\"Epoch {epoch+1}/{epochs}\", leave=True, ncols=120, unit=' batch')\n",
    "    for step in loader:\n",
    "        batch = dataset.getitems(B)\n",
    "        x_0_0 = [batch['x_0_0'][...,:3],batch['x_0_0'][...,3:]]         # Initial condition inferred vector features\n",
    "        x_s_0 = [batch['x_s_0'][...,:3],batch['x_s_0'][...,3:]]         # Final condition inferred vector features\n",
    "        v_0_0 = [torch.zeros_like(x_0_0[0],device=device)]              # Initial auxillary vector features\n",
    "        z_0_0 = [mass.unsqueeze(dim=0).expand(B,22), \n",
    "                 node_features['charge'].unsqueeze(dim=0).expand(B,22)] # Initial auxillary scalar features\n",
    "        t_diff = batch['t_diff']                                        # Diffusion time\n",
    "        s_phys = batch['s_phys']                                        # Physical time\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss_list = DDPM.loss(x_s_t, x_0_0, v_0_0, z_0_0, t_diff, s_phys, flatten=True)\n",
    "        pos_loss, mom_loss = loss_list\n",
    "        loss = pos_loss + mom_loss\n",
    "        loss.backward()\n",
    "\n",
    "        if grad_clipping != 0:\n",
    "            # Needs to be inspected. Does not work as intended.\n",
    "            torch.nn.utils.clip_grad_norm_(DDPM.parameters(), max_norm=grad_clipping)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        loader.set_postfix(\n",
    "            batch=f\"{int((step+1)/B)}/{int(epoch_size/B)}\",\n",
    "            loss=f\"{loss.item():.6f}\",\n",
    "            pos=f\"{pos_loss.item():.4e}\",\n",
    "            mom=f\"{mom_loss.item():.4e}\"\n",
    "        )\n",
    "\n",
    "        if wandb_step % log_interval == 0:\n",
    "            wandb.log({\n",
    "                \"loss/total\": loss.item(),\n",
    "                \"loss/position\": pos_loss.item(),\n",
    "                \"loss/momentum\": mom_loss.item(),\n",
    "                \"lr\": scheduler.get_last_lr()[0],\n",
    "            }, step=wandb_step)\n",
    "\n",
    "            # Log gradients and parameters\n",
    "            for name_, param in DDPM.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    wandb.log({f\"gradients/{name_}\": wandb.Histogram(param.grad.cpu().data.numpy())}, step=wandb_step)\n",
    "                wandb.log({f\"params/{name_}\": wandb.Histogram(param.cpu().data.numpy())}, step=wandb_step)\n",
    "\n",
    "        # if wandb_step % plot_interval == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         # Sample the trajectory\n",
    "        #         reverse_marginal = DDPM.sample_reverse_marginal([x_0_0_[:64] for x_0_0_ in x_0_0], [v_0_0_[:64] for v_0_0_ in v_0_0], [z_0_0_[:64] for z_0_0_ in z_0_0], 0, s_phys[:64])\n",
    "                \n",
    "        #         plot_hist_vs_normal(reverse_marginal[0], \"Position Reverse Output vs Standard Normal\")\n",
    "        #         plot_hist_vs_normal(reverse_marginal[1], \"Momentum Reverse Output vs Standard Normal\")\n",
    "            \n",
    "        #         del reverse_marginal\n",
    "\n",
    "        if wandb_step % save_interval == 0:\n",
    "            torch.save(DDPM, f\"model_{wandb_step}.pth\")\n",
    "\n",
    "        wandb_step += 1\n",
    "        scheduler.step()\n",
    "       \n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.6f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4e23648-4b56-42fb-99c5-d77a7059a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "top, node_features, mass, energy_dict = build_top_and_features(\"datasets/AlanaineDipeptideVacuum/alanine-dipeptide.prmtop\")\n",
    "atomic_numbers = [a.atomic_number for a in pmd.load_file(\"datasets/AlanaineDipeptideVacuum/alanine-dipeptide.prmtop\").atoms]\n",
    "save_pdb_with_bonds(dataset.getitem()['x_0_0'][0][:,:3],atomic_numbers,top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1df115e-518d-4445-a3b4-5a3e6efa3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "revsamples = DDPM.sample_reverse_marginal([x_0_0_.expand(64,22,3) for x_0_0_ in x_0_0], \n",
    "                                          [v_0_0_[:64] for v_0_0_ in v_0_0], \n",
    "                                          [z_0_0_[:64] for z_0_0_ in z_0_0], 0, \n",
    "                                          198*torch.ones(64,device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9b2a3-df80-40f0-af3a-f7db5235cc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d048a8c-48d8-4463-837a-1758516aa1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aced)",
   "language": "python",
   "name": "aced"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
