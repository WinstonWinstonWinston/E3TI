/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/libpyg.so)
  warnings.warn(f"An issue occurred while importing 'pyg-lib'. "
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/libpyg.so)
  warnings.warn(f"An issue occurred while importing 'torch-sparse'. "
wandb: Currently logged in as: winsaton (winsaton-univeristy-of-minnesota) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.22.1
wandb: Run data is saved locally in /users/1/sull1276/E3-Tensor-Interpolants/tests/logs/wandb/wandb/run-20251011_154257-ng6gu9bp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run E3TensorInterpolants
wandb: ‚≠êÔ∏è View project at https://wandb.ai/winsaton-univeristy-of-minnesota/e3ti
wandb: üöÄ View run at https://wandb.ai/winsaton-univeristy-of-minnesota/e3ti/runs/ng6gu9bp
wandb: logging graph, to disable use `wandb.watch(log_graph=False)`
GPU available: True (cuda), used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=gloo
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /users/1/sull1276/E3-Tensor-Interpolants/tests/logs/hydra/ckpt exists and is not empty.

  | Name     | Type                | Params | Mode 
---------------------------------------------------------
0 | embedder | EquilibriumEmbedder | 11.6 K | train
1 | model    | E3TIMLP             | 3.6 M  | train
---------------------------------------------------------
3.6 M     Trainable params
0         Non-trainable params
3.6 M     Total params
14.255    Total estimated model params size (MB)
24        Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1408. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/loss_velocity', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:434: It is recommended to use `self.log('val/loss_denoiser', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
/users/1/sull1276/micromamba/envs/e3ti/lib/python3.11/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 176. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
