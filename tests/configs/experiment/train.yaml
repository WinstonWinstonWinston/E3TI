# configs/experiments/train.yaml

# -------- lightning params --------
trainer:
  overfit_batches: 0
  min_epochs: 1 # prevents early stopping
  max_epochs: 200
  accelerator: gpu
  log_every_n_steps: 10
  deterministic: False
  strategy: ddp
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  accumulate_grad_batches: 1
  gradient_clip_val: 0.5
  gradient_clip_algorithm: norm
  precision: 32-true

checkpointer:
  dirpath: ${paths.ckpt_dir}
  save_last: True
  save_top_k: 5
  monitor: val/loss
  filename: epoch_{epoch}-step_{step}-loss_{val/loss:.4f}
  auto_insert_metric_name: False
  mode: min

# -------- wandb --------
wandb:
  name: ${project.name}
  project: E3TI
  save_dir: ${paths.wandb_dir}

wandb_watch:
  log: 'all'
  log_freq: 500

warm_start: null
warm_start_cfg_override: True