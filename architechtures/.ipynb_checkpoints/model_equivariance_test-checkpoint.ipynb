{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ab1d7a-9180-4465-a0ec-8342db2e03a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "╔═══════════════════════════════════════════════════╗\n",
      "║                                                   ║\n",
      "║  ██████╗   ██████╗    ██╗      ██████╗   ██╗  ██╗ ║\n",
      "║ ██╔════╝  ██╔══██╗   ██╔██╗    ██╔══██╗  ██║ ██╔╝ ║\n",
      "║ ╚█████╗   ██████╔╝  ██╔╝╚██╗   ██████╔╝  █████╔╝  ║\n",
      "║  ╚═══██╗  ██╔═══╝  ██╔╝  ╚██╗  ██╔══██╗  ██╔═██╗  ║\n",
      "║ ██████╔╝  ██║     ██╔╝    ╚██╗ ██║  ██║  ██║ ╚██╗ ║\n",
      "║ ╚═════╝   ╚═╝     ╚═╝      ╚═╝ ╚═╝  ╚═╝  ╚═╝  ╚═╝ ║\n",
      "║                                                   ║\n",
      "║     Statistical Physics Autodiff Research Kit     ║\n",
      "╚═══════════════════════════════════════════════════╝\n",
      "\n",
      "          V(r)           ψ, φ              q\n",
      "           │               │               │\n",
      "           ○               ○               ○\n",
      "         ╱ | ╲           ╱ | ╲           ╱ | ╲\n",
      "        ○  ○  ○         ○  ○  ○         ○  ○  ○\n",
      "         ╲ | ╱           ╲ | ╱           ╲ | ╱\n",
      "           ○               ○               ○\n",
      "           │               │               │\n",
      "          g(r)             F              E(q)\n",
      "\n",
      "It’s not undefined behavior if you don’t define expectations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.dirname(os.curdir)\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, \"../..\"))\n",
    "sys.path.append(parent_dir)\n",
    "import torch\n",
    "import system.units as units\n",
    "import system.topology as topology\n",
    "import system.box as box\n",
    "import forces.twobody as twobody\n",
    "import system.system as sys\n",
    "from integrators.NVT import NVT\n",
    "from integrators.NVE import NVE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import freud\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from utils import *\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import wandb\n",
    "device = \"cuda\"\n",
    "dtype=torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d13f4-0542-4782-bd5d-c9cb215c8acf",
   "metadata": {},
   "source": [
    "### Physical System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82eda1c2-b320-4e9f-9517-5bdd1251ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVE(dt=0.005)\n"
     ]
    }
   ],
   "source": [
    "top, node_features, mass, energy_dict = build_top_and_features(\"alanine-dipeptide.prmtop\")\n",
    "B = 2048\n",
    "pos = torch.tensor(pmd.load_file(\"alanine-dipeptide.pdb\").coordinates,dtype=dtype,device=device).unsqueeze(0).expand(B, -1, -1).contiguous()\n",
    "atomic_numbers = [a.atomic_number for a in pmd.load_file(\"alanine-dipeptide.pdb\").atoms]\n",
    "b = box.Box([1000,1000,1000],[\"s\",\"s\",\"s\"])\n",
    "u = units.UnitSystem.akma()\n",
    "mom = 0.5*torch.randn_like(pos)\n",
    "\n",
    "S = sys.System(pos, mom, mass, top, b, energy_dict, u, node_features)\n",
    "S.potential_energy()\n",
    "S.compile_force_fn()\n",
    "S.pos = S.pos - (S.mass.unsqueeze(-1) * S.pos).sum(dim=1, keepdim=True) / S.mass.sum(dim=1, keepdim=True).unsqueeze(-1)\n",
    "\n",
    "integrator = NVE(0.005)\n",
    "print(integrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71823f75-9f43-4235-bcf7-38b21e712113",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    M =S.mass.clone()\n",
    "    Q =S.node_features['charge'].clone()\n",
    "    P =S.mom.clone()\n",
    "    F =S.force().clone()\n",
    "    X =S.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07c3b3-de35-42fe-981e-858c6beaaf6a",
   "metadata": {},
   "source": [
    "### Equivariant Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131ac788-507f-403e-b671-8ee9185e3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorMatrixLayer(nn.Module):\n",
    "    def __init__(self, A, B):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(A,B))\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5**0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [b, N, A, d]\n",
    "        # weight: [A, B]\n",
    "        # output: [B, N, B, d]\n",
    "        return torch.einsum('AB,bnAd->bnBd', self.weight, x)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(in_channels={self.weight.shape[0]}, out_channels={self.weight.shape[1]})\"\n",
    "\n",
    "class EquivariantGraphNeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                f_1_layers, f_2_layers, f_3_layers, f_4_layers, f_5_layers,\n",
    "                readout_layers, scalar_embed_layers, vector_embed_layers,\n",
    "                message_passing_steps, p, activation_function,\n",
    "                device\n",
    "                ):\n",
    "\n",
    "        super(EquivariantGraphNeuralNetwork, self).__init__()\n",
    "\n",
    "         # --- extras ------------------------------------------------------------------------------------\n",
    "\n",
    "        # Suppose we expect many body behavior. It may be beneficial to do multiple steps of node communication to\n",
    "        # account for this. Therefore we have this extra parameter to indicate it.\n",
    "        \n",
    "        self.message_passing_steps = message_passing_steps\n",
    "\n",
    "        # it may be helpful to store these\n",
    "        \n",
    "        self.activation_function = activation_function\n",
    "        self.device = device\n",
    "        self.p = p\n",
    "\n",
    "        # I will be assuming the network is fully connected, the edge weight is the distance between nodes.\n",
    "         \n",
    "        # Fully connected graph (undirected, no self-loops)\n",
    "        num_nodes = 5\n",
    "        edges = list(combinations(range(num_nodes), 2))  # All unique pairs\n",
    "        self.edge_index = torch.tensor(np.array(edges).T,device=device)  # 2 x E\n",
    "\n",
    "        # --- message networks --------------------------------------------------------------------------------------\n",
    "\n",
    "        # --- scalar features --------------------------------------------------------\n",
    "\n",
    "        # f_1: s_j^(t), ||\\vec{x}_{i,j}|| \\rightarrow \\mathbb{R}                                                    (1)\n",
    "        \n",
    "        # f_1 is a mapping from scalar features and scalarized vector features to an associated message. This message is\n",
    "        # meant to be from node j to node i. If we take a permuation invariant aggregation operator (mean, sum) this \n",
    "        # scheme will be invariant to any permutative group action. Similarly, by scalarizing (applying the norm is a \n",
    "        # scalarizing type methdo) the vector features first we obtain invariance to any group action in SO(3). \n",
    "        # The corresponding message function can be read as\n",
    "\n",
    "        # m_i^(t) := s_i^(t) + \\sum_{j \\in Neigh} f_1(s_j^(t), ||\\vec{x}_{i,j}||)                                   (2)\n",
    "\n",
    "        # Crucially the way this is defined is ambiugous to the channels of the network. Each channel corresponds to some \n",
    "        # feature of the graph at the node. An example of different \"channels\" of a physical system would be the charge,\n",
    "        # mass, LJ parameters (given that mixing rules apply). Notably I am ignoring any features of a node which transform \n",
    "        # with respect to any element of the group. This choice allows me the freedom to apply non-linearties, mix information\n",
    "        # across channels, and use any functional form of f_1 I please. Note that whenever I write out the mapping like in (1)\n",
    "        # I am not being clear about the channels. Consider these functions on a per channel basis, each channel acts like (1).\n",
    "        \n",
    "        f_1_modules = []\n",
    "        for in_features, out_features in zip(f_1_layers[:-1], f_1_layers[1:]):\n",
    "            f_1_modules.append(nn.Linear(in_features, out_features))\n",
    "            f_1_modules.append(activation_function)\n",
    "            f_1_modules.append(torch.nn.Dropout(p=self.p))\n",
    "        self.f_1 = nn.Sequential(*f_1_modules[:-2]) # exclude dropout and activation on the last pass to put in (-infty,infty)\n",
    "\n",
    "        # Following the details of the PaiNN architechture the scalar message passing scheme we won't need  be anything beyond\n",
    "        # a definition of f_1. Notably a key aspect is the ability to apply any \n",
    "\n",
    "        # --- vector features --------------------------------------------------------\n",
    "\n",
    "        # f_2: s_j^(t), ||\\vec{x}_{i,j}|| \\rightarrow \\mathbb{R}                                                    (3)\n",
    "\n",
    "        # f_2 is exactly the same type of network as f_1. The reason for the distinction is to emphasize that they are \n",
    "        # explictly different networks. f_2 will act as a gate for the vector feature coming from node j. I like to think\n",
    "        # about each node like a hairy point. Each hair of a persons haircut is not always important for their overall look.\n",
    "        # Consider two cases, 1) a plain haired individual and 2) a power donut, the lary david type. Each hair on the sides\n",
    "        # will be the same for both 1) and 2), implying there is nothing out of the ordinary. However, there is a clear \n",
    "        # distinction between the top of each head. Due to our mapping f_1 taking in scalar features (one of which could be\n",
    "        # age in this example) we may want to use the age to put emphasis on the top of head hairs in order to distinguish\n",
    "        # if this person is balding or not. The same can be said for the side hairs, we want to unweight this trait because\n",
    "        # there is no indication in the scalar features that it is even needed. This situation can be compared with \n",
    "        # haircut 3) Skrillex's, his haircut has one side shaved completely. Another possible scalar feature might be career.\n",
    "        # Using this we would know to weight hairs on the side more due to many EDM artists and DJs like Skrillex having such \n",
    "        # a haircut. Therefore we can consider the function f_2 as the vector feature gating as informed by the scalar features\n",
    "        # and the scalarized vector features.\n",
    "\n",
    "        f_2_modules = []\n",
    "        for in_features, out_features in zip(f_2_layers[:-1], f_2_layers[1:]):\n",
    "            f_2_modules.append(nn.Linear(in_features, out_features))\n",
    "            f_2_modules.append(activation_function)\n",
    "            f_2_modules.append(torch.nn.Dropout(p=self.p))\n",
    "        self.f_2 = nn.Sequential(*f_2_modules[:-2]) # exclude dropout and activation on the last pass to put in (-infty,infty)\n",
    "\n",
    "\n",
    "        # f_3: s_j^(t), ||\\vec{x}_{i,j}|| \\rightarrow \\mathbb{R}                                                    (4)\n",
    "        \n",
    "        # f_3 is again more of the same. The only difference is that the gating is not done on the channel based features, \n",
    "        # rather this is on the edge based distance feature \\vec{x}_{i,j}. \n",
    "\n",
    "        f_3_modules = []\n",
    "        for in_features, out_features in zip(f_3_layers[:-1], f_3_layers[1:]):\n",
    "            f_3_modules.append(nn.Linear(in_features, out_features))\n",
    "            f_3_modules.append(activation_function)\n",
    "            f_3_modules.append(torch.nn.Dropout(p=self.p))\n",
    "        self.f_3 = nn.Sequential(*f_3_modules[:-2]) # exclude dropout and activation on the last pass to put in (-infty,infty)\n",
    "\n",
    "        # Together these make up the full vector message like\n",
    "\n",
    "        #  \\vec{m}_i^(t) := \\vec{v}_i^(t) + \\sum_{j \\in Neigh} [\n",
    "        #          f_2(s_j^(t), ||\\vec{x}_{i,j}||) \\circ \\vec{v_j}^(t) +  f_3(s_j^(t), ||\\vec{x}_{i,j}||) \\circ \\vec{x_{i,j}}]  (5)\n",
    "\n",
    "        # --- update networks --------------------------------------------------------------------------------------\n",
    "\n",
    "        # The update networks act the similarly as the networks above. The key difference between the update and the message \n",
    "        # is there is no aggregation and there is no communication between the nodes. This implies there is no dependence on the\n",
    "        # \\vec{x_{i,j}}. This gives f_4 and f_5 as maps of the form. Also we do not interperet f_4 as a gating network as it \n",
    "        # just shifts the message to obtain the next scalar feature.\n",
    "\n",
    "        # f_4: \\vec{m}_i^(t), ||\\vec{m}_i^(t)|| \\rightarrow \\mathbb{R}                                             (6)\n",
    "\n",
    "        # f_5: \\vec{m}_i^(t), ||\\vec{m}_i^(t)|| \\rightarrow \\mathbb{R}                                             (7)\n",
    "\n",
    "        # --- scalar features --------------------------------------------------------\n",
    "        \n",
    "        f_4_modules = []\n",
    "        for in_features, out_features in zip(f_4_layers[:-1], f_4_layers[1:]):\n",
    "            f_4_modules.append(nn.Linear(in_features, out_features))\n",
    "            f_4_modules.append(activation_function)\n",
    "            f_4_modules.append(torch.nn.Dropout(p=self.p))\n",
    "        self.f_4 = nn.Sequential(*f_4_modules[:-2]) # exclude dropout and activation on the last pass to put in (-infty,infty)\n",
    "\n",
    "        #  s_i^(t+1) := m_i^(t) + f_4(m_i^(t), ||\\vec{m}_{i}^(t)||)                                                 (8)\n",
    "\n",
    "        # --- vector features --------------------------------------------------------\n",
    "        \n",
    "        f_5_modules = []\n",
    "        for in_features, out_features in zip(f_5_layers[:-1], f_5_layers[1:]):\n",
    "            f_5_modules.append(nn.Linear(in_features, out_features))\n",
    "            f_5_modules.append(activation_function)\n",
    "            f_5_modules.append(torch.nn.Dropout(p=self.p))\n",
    "        self.f_5 = nn.Sequential(*f_5_modules[:-2]) # exclude dropout and activation on the last pass to put in (-infty,infty)\n",
    "\n",
    "        # At this point it may be beneficial to out learning to introduce the U and V matricies of the update function in a \n",
    "        # PaiNN network. I will not be doing this for pedagogical reasoning as of now. Perhaps if the learning is beans I will\n",
    "        # come back and add it. \n",
    "\n",
    "        #  \\vec{v}_i^(t+1) := \\vec{m}_i^(t) + f_5(m_i^(t), ||\\vec{m}_{i}^(t)||) \\circ \\vec{m}_{i}^(t)                (9)\n",
    "\n",
    "        # --- readout --------------------------------------------------------------------------------------\n",
    "\n",
    "        # Once all the message passing is complete there is a final readout step. Because we are intending to predict\n",
    "        # vector features (momentum and position later) the readout will act on the vector features by taking a linear\n",
    "        # combination of the vector channels. Linear combinations and rotations commute so this will be all good. \n",
    "        # Above we did not need to worry about permutation invariance because the graph based message passing handled it\n",
    "        # for us. Here we can avoid any issues by not mixing nodes vector features. This would imply the vector readout\n",
    "        # is only going to act like C -> 6, where the first three are the new node position and the last are the new\n",
    "        # momentum components. Mathematically this looks like\n",
    "\n",
    "        # G: \\vec{m}_i \\rightarrow \\mathbb{R}^(6*3)                                                                 (10)\n",
    "\n",
    "        # G(i) = M \\cdot \\vec{v}_i^(t+1)  where [6 x C] \\cdot [C x 3] \\rightarrow [6 x 3] linearly                  (11)\n",
    "        \n",
    "        self.readout = VectorMatrixLayer(readout_layers[0][0],readout_layers[1][0])\n",
    "\n",
    "        # --- embeddings ------------------------------------------------------------------------------------\n",
    "\n",
    "        # The initial scalar and vector features at each node are not of the channel shape. This provides a managerial issue\n",
    "        # for the code. We really dont want to have multiple message and update functions as this causes headache. Therefore\n",
    "        # we opt to just transform them into the correct shape initially. Just like the readout we need to be careful to\n",
    "        # ensure that we remain equivariant. This means we may have a matrix for the vector features and then an MLP for the\n",
    "        # scalar ones. \n",
    "\n",
    "        # Embed_vec(i) = M \\cdot \\vec{p}_i  where [C x num(p)] \\cdot [num(p) x 3] \\rightarrow [6 x 3] linearly       (12)\n",
    "\n",
    "        # Embed_scalar(i) = MLP(p_i)                                                                                 (13)\n",
    "\n",
    "        scalar_embed_modules = []\n",
    "        for in_features, out_features in zip(scalar_embed_layers[:-1], scalar_embed_layers[1:]):\n",
    "            scalar_embed_modules.append(nn.Linear(in_features, out_features))\n",
    "            scalar_embed_modules.append(activation_function)\n",
    "            scalar_embed_modules.append(torch.nn.Dropout(p=self.p))\n",
    "        self.scalar_embed = nn.Sequential(*scalar_embed_modules[:-2])\n",
    "\n",
    "        self.vector_embed = VectorMatrixLayer(vector_embed_layers[0][0],vector_embed_layers[1][0])\n",
    "\n",
    "    def message(self, vectorial_feat: Tensor, scalar_feat: Tensor, node_pos: Tensor, edge_index: Tensor):\n",
    "        r\"\"\"\n",
    "        Parameters:\n",
    "            vectorial_feat (torch.Tensor):\n",
    "                Vectorial representations. Shape [B, N, C, 3]\n",
    "            scalar_feat (torch.Tensor):\n",
    "                Scalar representations. Shape [B, N, C]\n",
    "            edge_index (torch.Tensor):\n",
    "                Shape [2, E]\n",
    "            node_pos (torch.Tensor):\n",
    "                Atom's 3D coordinates. Shape [B, N, 3]\n",
    "\n",
    "        Returns:\n",
    "            vectorial_message (torch.Tensor):\n",
    "                Shape [B, N, C, 3]\n",
    "            scalar_message (torch.Tensor):\n",
    "                Shape [B, N, C]\n",
    "        \"\"\"\n",
    "        B, N, E = node_pos.shape[0], node_pos.shape[1], edge_index.shape[-1]\n",
    "        source, target = edge_index # E, E\n",
    "        Adj = torch.zeros(N, N, device=self.device)\n",
    "        Adj[target, source] = 1  \n",
    "\n",
    "        # vectorial quantity\n",
    "        # compute all pairwise differences\n",
    "        x_ij_full = node_pos[:, :, None, :] - node_pos[:, None, :, :]  # broadcasted over batch [B, N, N, 3]\n",
    "        \n",
    "        # create a mask to exclude diagonal of an N,N matrix\n",
    "        mask = ~torch.eye(N, dtype=bool, device=node_pos.device) #  [N, N]\n",
    "        \n",
    "        # apply mask across batch, reshape\n",
    "        x_ij_matrix = x_ij_full[:, mask].view(B, N, N - 1, 3) # [B, N, N-1, 3]\n",
    "\n",
    "        # scalar quantity\n",
    "        abs_x_ij = torch.sum(x_ij_matrix ** 2, dim = -1) ** 0.5 # [B, N, N-1]\n",
    "\n",
    "        # cat features for f_something\n",
    "        cat_feats = torch.cat([scalar_feat, abs_x_ij],dim=-1) # [B, N, C + N-1]\n",
    "        \n",
    "        # apply non-linearity\n",
    "        transformed_scalar_feat = self.f_1(cat_feats) # [B, N, C]\n",
    "        transformed_vector_feat = self.f_2(cat_feats) # [B, N, C]\n",
    "        transformed_edge_feat   = self.f_3(cat_feats) # [B, N, C]\n",
    "\n",
    "        # communicate scalars between nodes\n",
    "        neighbor_sum_scalar = torch.einsum('ij,bjd->bid', Adj.to(dtype=transformed_scalar_feat.dtype), transformed_scalar_feat) # [B, N, C]\n",
    "\n",
    "        # communicate vectors between nodes\n",
    "        # unsqueeze on the transformed_vector_feat allows for conversion from [B, N, C] to [B, N, C, 1] so it gets projected\n",
    "        # along all vector components.\n",
    "        neighbor_sum_vector = torch.einsum('ij,bjck->bick',Adj,transformed_vector_feat.unsqueeze(-1)*vectorial_feat) # [B, N, C, 3]\n",
    "\n",
    "        # communicate edge feats between nodes\n",
    "        # The is transformed_edge_feat_expanded is duplicating along the N dimension. Giving B, N, N, C. This \n",
    "        # then gets the diagonal excluded. This is to prevent messages i-> itself In hindsight I shouldve probably just done \n",
    "        # einsum with the full distance matrix, the diagonal zeros woulda taken care of it.\n",
    "        transformed_edge_feat_expanded = transformed_edge_feat[:, None, :, :].expand(B, N, N, C)[:, mask].view(B, N, N - 1, C)\n",
    "        neighbor_sum_edge = torch.einsum('bnik,bnij->bnkj', transformed_edge_feat_expanded, x_ij_matrix) # [B, N, C, 3]\n",
    "\n",
    "        # compute scalar message\n",
    "        scalar_feat = scalar_feat + neighbor_sum_scalar  # [B, N, C]\n",
    "        vectorial_feat = vectorial_feat + neighbor_sum_edge + neighbor_sum_vector  # [B, N, C, 3]\n",
    "        \n",
    "        return vectorial_feat, scalar_feat\n",
    "        \n",
    "    def update(self, vectorial_feat: Tensor, scalar_feat: Tensor):\n",
    "        r\"\"\"\n",
    "        Parameters:\n",
    "            vectorial_feat (torch.Tensor):\n",
    "                Vectorial representations. Shape [B, N, embedding_dim, 3]\n",
    "            scalar_feat (torch.Tensor):\n",
    "                Scalar representations. Shape [B, N, embedding_dim]\n",
    "\n",
    "        Returns:\n",
    "            vectorial_update (torch.Tensor):\n",
    "                Shape [B, N, embedding_dim, 3]\n",
    "            scalar_update (torch.Tensor):\n",
    "                Shape [B, N, embedding_dim]\n",
    "        \"\"\"\n",
    "        scalarize_vectorial_feat = (vectorial_feat**2).sum(dim=-1)**0.5 # [B, N, C]\n",
    "\n",
    "        #                [B, N, C + C] ->  [B, N, C]\n",
    "        scalar_delta = self.f_4(torch.cat([scalar_feat, scalarize_vectorial_feat],dim=-1)) # [B, N, C]\n",
    "\n",
    "        vector_gate = self.f_5(torch.cat([scalar_feat, scalarize_vectorial_feat],dim=-1)) # [B, N, C]\n",
    "        vector_delta = vector_gate.unsqueeze(dim=-1)*vectorial_feat # [B, N, C, 3]\n",
    "\n",
    "        vectorial_update = vectorial_feat + vector_delta\n",
    "        scalar_update = scalar_feat + scalar_delta\n",
    "\n",
    "        return vectorial_update, scalar_update\n",
    "\n",
    "    def forward(self, mass, charge, momentum, force, position):\n",
    "        r\"\"\"\n",
    "        Parameters:\n",
    "            mass (torch.Tensor):\n",
    "                Mass of each atom/node, scalar feature. Shape [B, N]\n",
    "            charge (torch.Tensor):\n",
    "                Charge of each atom/node, scalar feature. Shape [B, N]\n",
    "            momentum (torch.Tensor):\n",
    "                Momentum of each atom/node, vector feature. Shape [B, N, 3]\n",
    "            force (torch.Tensor):\n",
    "                Force of each atom/node, vector feature. Shape [B, N, 3]\n",
    "            position (torch.Tensor):\n",
    "                Position of each atom/node, vector feature. Shape [B, N, 3]\n",
    "\n",
    "        Returns:\n",
    "            momentum_later (torch.Tensor):\n",
    "                Momentum of each atom/node after lag time, vector feature. Shape [B, N, 3]\n",
    "            position_later (torch.Tensor):\n",
    "                Position of each atom/node after lag time, vector feature. Shape [B, N, 3]\n",
    "        \"\"\"\n",
    "\n",
    "        # embed the charge and the mass\n",
    "        # [B, N, 2] -> [B, N, C]\n",
    "        scalar_feat = self.scalar_embed(torch.cat([mass.unsqueeze(dim=-1),charge.unsqueeze(dim=-1)],dim=-1))\n",
    "\n",
    "        # embed the force and momentum\n",
    "        # [B, N, 2, 3] -> [B, N, C, 3]\n",
    "        vectorial_feat = self.vector_embed(torch.stack([momentum, force], dim=2))\n",
    "\n",
    "        # start a loop over the number of message + update steps\n",
    "        for t in range(self.message_passing_steps):\n",
    "            # apply message\n",
    "            vectorial_feat_t, scalar_feat_t = self.message(vectorial_feat, scalar_feat, position, self.edge_index)\n",
    "            # apply update\n",
    "            vectorial_feat, scalar_feat = self.update(vectorial_feat_t, scalar_feat_t)\n",
    "            \n",
    "        # readout the new position and momentum from a linear combination of the chanels\n",
    "        # [B, N, C, 3] -> [B, N, 2, 3]\n",
    "        final_readout = self.readout(vectorial_feat)\n",
    "\n",
    "        # split channels into position and momentum\n",
    "        position_later = final_readout[:,:,0]\n",
    "        momentum_later = final_readout[:,:,1]\n",
    "\n",
    "        return momentum_later, position_later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54e00cf-c6be-4837-a670-3a9e5c87db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean ε_momentum over 100 rotations: 1.43e-06\n",
      "mean ε_position over 100 rotations: 4.94e-06\n",
      "\n",
      "Median momentum RMSD averaged over 100 rotations: 0.00015666961669921875\n",
      "Median position RMSD difference averaged over 100 rotations: 9.467899799346924e-05\n",
      "\n",
      "Mean momentum RMSD averaged over 100 rotations: 0.0020901413679104345\n",
      "Mean position RMSD difference averaged over 100 rotations: 0.0010432152005589387\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = 32\n",
    "N = 22\n",
    "\n",
    "f_1_layers = [C + N-1, C + N - 1, C]\n",
    "f_2_layers = [C + N-1, C + N - 1, C]\n",
    "f_3_layers = [C + N-1, C + N - 1, C]\n",
    "f_4_layers = [C + C,   C + C    , C]\n",
    "f_5_layers = [C + C,   C + C    , C]\n",
    "\n",
    "readout_layers      = [(C,3), (2,3)]\n",
    "scalar_embed_layers = [2, C, C, C]\n",
    "vector_embed_layers = [(2,3), (C,3)]\n",
    "                \n",
    "message_passing_steps = 5\n",
    "p = 0\n",
    "activation_function = nn.Tanh()\n",
    "\n",
    "EGNN = EquivariantGraphNeuralNetwork(f_1_layers, f_2_layers, f_3_layers, f_4_layers, f_5_layers,\n",
    "                readout_layers, scalar_embed_layers, vector_embed_layers,\n",
    "                message_passing_steps, p,  activation_function,\n",
    "                device)\n",
    "EGNN.to(EGNN.device)\n",
    "\n",
    "num_iters = 100\n",
    "\n",
    "median_total_mom_error = []\n",
    "median_total_pos_error = []\n",
    "\n",
    "mean_total_mom_error = []\n",
    "mean_total_pos_error = []\n",
    "\n",
    "eps_mom   = 0.0\n",
    "eps_pos   = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for blah in range(num_iters):\n",
    "        # Sample rotation\n",
    "        RP, R, _ = random_rotation_3d(P)      # rotate positions\n",
    "        RF, _, _ = random_rotation_3d(F, R)   # share the same R for everything\n",
    "        RX, _, _ = random_rotation_3d(X, R)\n",
    "    \n",
    "        mom_rot, pos_rot   = EGNN(M, Q, RP, RF, RX)   # rotated inputs\n",
    "        mom_ref, pos_ref   = EGNN(M, Q, P,  F,  X)    # original inputs\n",
    "        Rmom_ref, _, _     = random_rotation_3d(mom_ref, R) # rotate the output of the original inputs\n",
    "        Rpos_ref, _, _     = random_rotation_3d(pos_ref, R)  \n",
    "    \n",
    "        # median errors\n",
    "        median_total_mom_error.append(torch.median((mom_rot - Rmom_ref)**2).item()**0.5)\n",
    "        median_total_pos_error.append(torch.median((pos_rot - Rpos_ref)**2).item()**0.5)\n",
    "    \n",
    "        # mean errors\n",
    "        mean_total_mom_error.append(torch.mean((mom_rot - Rmom_ref)**2).item()**0.5)\n",
    "        mean_total_pos_error.append(torch.mean((pos_rot - Rpos_ref)**2).item()**0.5)\n",
    "\n",
    "        # relative equivariance error ε = ||Δ|| / ||ref||\n",
    "        eps_mom += torch.linalg.vector_norm(mom_rot - Rmom_ref) / (\n",
    "                   torch.linalg.vector_norm(mom_ref) + 1e-12)\n",
    "        eps_pos += torch.linalg.vector_norm(pos_rot - Rpos_ref) / (\n",
    "                   torch.linalg.vector_norm(pos_ref) + 1e-12)\n",
    "    \n",
    "    eps_mom /= num_iters\n",
    "    eps_pos /= num_iters\n",
    "    \n",
    "    print(f\"mean relative error in momentum over {num_iters} rotations: {eps_mom:.2e}\")\n",
    "    print(f\"mean relative error in position over {num_iters} rotations: {eps_pos:.2e}\")\n",
    "    print()\n",
    "\n",
    "    print(f\"Median momentum RMSD averaged over {num_iters} rotations:\", sum(median_total_mom_error) / num_iters)\n",
    "    print(f\"Median position RMSD difference averaged over {num_iters} rotations:\", sum(median_total_pos_error) / num_iters)\n",
    "    print()\n",
    "    \n",
    "    print(f\"Mean momentum RMSD averaged over {num_iters} rotations:\", sum(mean_total_mom_error) / num_iters)\n",
    "    print(f\"Mean position RMSD difference averaged over {num_iters} rotations:\", sum(mean_total_pos_error) / num_iters)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aced)",
   "language": "python",
   "name": "aced"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
