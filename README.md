This repository separates **models**, **experiments**, **data**, and **configs** so you can swap architectures, datasets, and hyperâ€‘parameters with minimal friction.

---

## ğŸ“ Repository structure

```text
.
â”œâ”€â”€ models/          # PyTorch modules, losses, utilities
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ experiments/     # Entryâ€‘points: train.py, inference.py, evaluate.py, etc.
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ data/            # Raw or processed datasets (gitâ€‘ignored by default)
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ ...
â””â”€â”€ configs/         # Hydra configuration files (YAML)
    â”œâ”€â”€ config.yaml  # master config (defaults list)
    â”œâ”€â”€ model/       # architectureâ€‘specific configs
    â”œâ”€â”€ data/        # datasetâ€‘specific configs
    â””â”€â”€ experiment/  # training, inference, evaluation settings
```

### Folder breakdown

| Folder           | Purpose                                                                                                                |
| ---------------- | ---------------------------------------------------------------------------------------------------------------------- |
| **models/**      | All PyTorch `nn.Module`s and subâ€‘modules. Keep each architecture in its own file for clarity.                          |
| **experiments/** | Scripts that *do* thingsâ€”training, inference, evaluation, hyperâ€‘sweeps. Each should be Hydraâ€‘aware.                    |
| **data/**        | Storage for datasets or links to external sources. Add a `README.md` explaining how to download or preâ€‘process.        |
| **configs/**     | A composable config tree for Hydra. Organise by domain (`model/`, `data/`, `experiment/`) so overrides stay intuitive. |

---

## ğŸš€ Quick start

Please inspect `setup_umn.sh` before running to ensure it is correct for your machine (paths, modules, etc).

```bash
# 1. Clone and install
git clone https://github.com/SAMPEL-Group/E3-Tensor-Interpolants.git
cd E3-Tensor-Interpolants
chmod +x setup_umn.sh
./setup_umn.sh
```

# 2. Load modules 
```bash
module load gcc/8.2.0
module load ompi/3.1.6/gnu-8.2.0
module load cuda/11.8.0-gcc-7.2.0-xqzqlf2
```

# 3. Train (override any Hydra key on the CLI)
```python
python experiments/train.py \
  model=resnet18 \
  data=cifar10 \
  experiment=baseline \
  trainer.max_epochs=100 \
  optimizer.lr=1e-3
```

# 4. Inference
```python
python experiments/inference.py \
  checkpoint=outputs/2025-07-21/ckpt_best.pt \
  data=test_set
```

# 5. Evaluation
```python
python experiments/evaluate.py \
  checkpoint=outputs/2025-07-21/ckpt_best.pt \
  metrics=accuracy,f1
```

Hydra creates a timestamped subâ€‘folder inside `outputs/` for every run, logging configs, stdout, and model checkpoints for perfect reproducibility.

---

## ğŸ› ï¸ Customising configs

1. **Create a new YAML** (e.g. `configs/model/wideresnet.yaml`).
2. Add it to the `defaults:` list in `configs/config.yaml` or pass `model=wideresnet` on the CLI.
3. Profitâ€”no code changes required.

---